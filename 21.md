Chapter 21: Additional topics in causal inference
================
A. Solomon Kurz
2021-10-08

# Additional topics in causal inference

> The previous chapters described causal inference strategies that
> assume ignorability of exposure or treatment assignment. It is
> reasonable to be concerned about this assumption, however. After all,
> when are we really confident that we have measured *all* confounders?
> This chapter explores several alternative causal inference strategies
> that rely on slightly different sets of assumptions that may be more
> plausible in certain settings. (p. 421, *emphasis* in the original)

## 21.1 Estimating causal effects indirectly using instrumental variables

> In some situations when the argument for ignorability of the treatment
> assignment seems weak, there may exist another variable that does
> appear to be randomly assigned or can be considered as such. If this
> variable, called the *instrument*, *z*, is predictive of the
> treatment, *T*, then we *may* be able to use it to isolate a
> particular kind of targeted causal estimand. The instrument should
> only affect the treatment assignment but not have a direct effect on
> the outcome, an *exclusion restriction* that we explain more precisely
> below. (p. 421, *emphasis* in the original)

### Example: a randomized-encouragement design.

Load the `sesame.csv` data.

``` r
library(tidyverse)

sesame <- read_csv("ROS-Examples-master/Sesame/data/sesame.csv")

glimpse(sesame)
```

    ## Rows: 240
    ## Columns: 32
    ## $ rownames   <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …
    ## $ id         <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …
    ## $ site       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…
    ## $ sex        <dbl> 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1,…
    ## $ age        <dbl> 66, 67, 56, 49, 69, 54, 47, 51, 69, 53, 58, 58, 49, 64, 58,…
    ## $ viewcat    <dbl> 1, 3, 3, 1, 4, 3, 3, 2, 4, 3, 2, 4, 1, 2, 2, 3, 2, 4, 3, 3,…
    ## $ setting    <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…
    ## $ viewenc    <dbl> 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2,…
    ## $ prebody    <dbl> 16, 30, 22, 23, 32, 29, 23, 32, 27, 30, 25, 21, 28, 26, 23,…
    ## $ prelet     <dbl> 23, 26, 14, 11, 47, 26, 12, 48, 44, 38, 48, 25, 8, 11, 15, …
    ## $ preform    <dbl> 12, 9, 9, 10, 15, 10, 11, 19, 18, 17, 14, 13, 9, 15, 9, 17,…
    ## $ prenumb    <dbl> 40, 39, 9, 14, 51, 33, 13, 52, 42, 31, 38, 29, 13, 21, 16, …
    ## $ prerelat   <dbl> 14, 16, 9, 9, 17, 14, 11, 15, 15, 10, 16, 16, 8, 10, 9, 12,…
    ## $ preclasf   <dbl> 20, 22, 8, 13, 22, 14, 12, 23, 20, 17, 18, 21, 12, 15, 11, …
    ## $ postbody   <dbl> 18, 30, 21, 21, 32, 27, 22, 31, 32, 32, 26, 17, 20, 26, 28,…
    ## $ postlet    <dbl> 30, 37, 46, 14, 63, 36, 45, 47, 50, 52, 52, 29, 16, 28, 21,…
    ## $ postform   <dbl> 14, 17, 15, 13, 18, 14, 12, 18, 17, 19, 15, 15, 9, 15, 10, …
    ## $ postnumb   <dbl> 44, 39, 40, 19, 54, 39, 44, 51, 48, 52, 42, 40, 18, 35, 22,…
    ## $ postrelat  <dbl> 14, 14, 9, 8, 14, 16, 12, 17, 14, 17, 10, 10, 10, 16, 10, 1…
    ## $ postclasf  <dbl> 23, 22, 19, 15, 21, 24, 15, 23, 24, 24, 17, 19, 13, 14, 17,…
    ## $ peabody    <dbl> 62, 8, 32, 27, 71, 32, 28, 38, 49, 32, 43, 58, 39, 43, 56, …
    ## $ agecat     <dbl> 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,…
    ## $ encour     <dbl> 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,…
    ## $ `_Isite_2` <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
    ## $ `_Isite_3` <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
    ## $ `_Isite_4` <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
    ## $ `_Isite_5` <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
    ## $ regular    <dbl> 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,…
    ## $ watched    <dbl> 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,…
    ## $ encouraged <dbl> 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,…
    ## $ y          <dbl> 30, 37, 46, 14, 63, 36, 45, 47, 50, 52, 52, 29, 16, 28, 21,…
    ## $ pretest    <dbl> 23, 26, 14, 11, 47, 26, 12, 48, 44, 38, 48, 25, 8, 11, 15, …

``` r
head(sesame)
```

    ## # A tibble: 6 × 32
    ##   rownames    id  site   sex   age viewcat setting viewenc prebody prelet
    ##      <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>  <dbl>
    ## 1        1     1     1     1    66       1       2       1      16     23
    ## 2        2     2     1     2    67       3       2       1      30     26
    ## 3        3     3     1     1    56       3       2       2      22     14
    ## 4        4     4     1     1    49       1       2       2      23     11
    ## 5        5     5     1     1    69       4       2       2      32     47
    ## 6        6     6     1     2    54       3       2       2      29     26
    ## # … with 22 more variables: preform <dbl>, prenumb <dbl>, prerelat <dbl>,
    ## #   preclasf <dbl>, postbody <dbl>, postlet <dbl>, postform <dbl>,
    ## #   postnumb <dbl>, postrelat <dbl>, postclasf <dbl>, peabody <dbl>,
    ## #   agecat <dbl>, encour <dbl>, _Isite_2 <dbl>, _Isite_3 <dbl>, _Isite_4 <dbl>,
    ## #   _Isite_5 <dbl>, regular <dbl>, watched <dbl>, encouraged <dbl>, y <dbl>,
    ## #   pretest <dbl>

Because one cannot force children to watch Sesame Street, one can only
randomize whether the children were encouraged to watch the show. Also,
some of the children who were not explicitly encouraged will still watch
the show. Thus, this is study is called a *randomized encouragement
design*.

``` r
sesame %>% 
  count(encouraged, watched)
```

    ## # A tibble: 4 × 3
    ##   encouraged watched     n
    ##        <dbl>   <dbl> <int>
    ## 1          0       0    40
    ## 2          0       1    48
    ## 3          1       0    14
    ## 4          1       1   138

### Compliance as an intermediate potential outcome.

### Assumptions for instrumental variables estimation.

#### Ignorability of the instrument.

The assumption of “*ignorability of the instrument* with respect to the
potential outcomes (both for the primary outcome of interest and the
treatment variable),” *y*<sup>0</sup>, *y*<sup>1</sup> ⊥ *z*, is
“satisfied in a randomized experiment (assuming the randomization was
pristine), assuming, as always, that any design features are reflected
in the analysis” (p. 422, *emphasis* in the original).

#### Monotonicity.

> In defining never-takers and always-takers, we assumed that there were
> no children who would watch if they were not encouraged but who would
> *not* watch if they *were* encouraged; that is, we assumed that there
> were no defiers. Formally this is called the *monotonicity
> assumption*, and it will not necessarily hold in practice, though
> there are many situations in which it is defensible. (p. 423,
> *emphasis* in the original)

#### Nonzero association between instrument and treatment variable.

> To demonstrate how we can use the instrument to obtain a causal
> estimate of the treatment effect in our example, first consider that
> about 90% of those encouraged watched the show regularly; by
> comparison, only 55% of those not encouraged watched the show
> regularly. Therefore, if we are interested in the effect of actually
> viewing the show, we should focus on the 35% of the treatment
> population who decided to watch the show because they were encouraged
> but who otherwise would not have watched the show. If the instrument
> (encouragement) did not affect regular watching, then we could not
> proceed. (p. 423)

#### Exclusion restriction.

> To estimate the effect of viewing for those children whose viewing
> behavior would have been affected by the encouragement (the induced
> watchers), we must make another important assumption, called the
> *exclusion restriction*. This assumption says for those children whose
> behavior would not have been changed by the encouragement
> (never-takers and always-takers) there is no effect of encouragement
> on outcomes. (p. 423, *emphasis* in the original)

### Derivation of instrumental variables estimation with complete data (including unobserved potential outcomes).

Make the data in Figure 21.1.

``` r
fig21.1 <-
  tibble(unit = 1:20,
         t0 = rep(c(0:1, 0:1), times = c(6, 4, 6, 4)),
         t1 = rep(c(1:0, 1:0, 1), times = c(4, 2, 8, 2, 4))) %>% 
  mutate(compliance = case_when(
    t0 == 0 & t1 == 1 ~ "complier",
    t0 == 0 & t1 == 0 ~ "never-taker",
    t0 == 1 & t1 == 1 ~ "always-taker"
  )) %>% 
  mutate(encouragement = rep(0:1, each = 10)) %>% 
  mutate(y0 = c(67, 72, 74, 68, 68, 70, 76, 74, 80, 82, 67, 72, 74, 68, 68, 70, 76, 74, 80, 82),
         y1 = c(76, 80, 81, 78, 68, 70, 76, 74, 80, 82, 76, 80, 81, 78, 68, 70, 76, 74, 80, 82)) %>% 
  mutate(effect = y1 - y0)

fig21.1
```

    ## # A tibble: 20 × 8
    ##     unit    t0    t1 compliance   encouragement    y0    y1 effect
    ##    <int> <int> <dbl> <chr>                <int> <dbl> <dbl>  <dbl>
    ##  1     1     0     1 complier                 0    67    76      9
    ##  2     2     0     1 complier                 0    72    80      8
    ##  3     3     0     1 complier                 0    74    81      7
    ##  4     4     0     1 complier                 0    68    78     10
    ##  5     5     0     0 never-taker              0    68    68      0
    ##  6     6     0     0 never-taker              0    70    70      0
    ##  7     7     1     1 always-taker             0    76    76      0
    ##  8     8     1     1 always-taker             0    74    74      0
    ##  9     9     1     1 always-taker             0    80    80      0
    ## 10    10     1     1 always-taker             0    82    82      0
    ## 11    11     0     1 complier                 1    67    76      9
    ## 12    12     0     1 complier                 1    72    80      8
    ## 13    13     0     1 complier                 1    74    81      7
    ## 14    14     0     1 complier                 1    68    78     10
    ## 15    15     0     0 never-taker              1    68    68      0
    ## 16    16     0     0 never-taker              1    70    70      0
    ## 17    17     1     1 always-taker             1    76    76      0
    ## 18    18     1     1 always-taker             1    74    74      0
    ## 19    19     1     1 always-taker             1    80    80      0
    ## 20    20     1     1 always-taker             1    82    82      0

If you were in the enviable (and unrealistic) position of having the
full array of potential outcomes you can compute each participant’s
treatment effect by hand. Then the intent-to-treat effect is the simple
average of those effects.

``` r
fig21.1 %>% 
  summarise(itt = sum(effect) / n())
```

    ## # A tibble: 1 × 1
    ##     itt
    ##   <dbl>
    ## 1   3.4

Note how, in Table 21.1, the individual-level causal effect is always
zero for both the never-takers and the always-takers.

Now note that the treatment effect for the compliers is higher.

``` r
fig21.1 %>% 
  filter(compliance == "complier") %>% 
  summarise(itt = sum(effect) / n())
```

    ## # A tibble: 1 × 1
    ##     itt
    ##   <dbl>
    ## 1   8.5

``` r
fig21.1 %>% 
  group_by(compliance == "complier") %>% 
  summarise(itt = mean(effect),
            n = n()) %>% 
  mutate(percent = n / sum(n))
```

    ## # A tibble: 2 × 4
    ##   `compliance == "complier"`   itt     n percent
    ##   <lgl>                      <dbl> <int>   <dbl>
    ## 1 FALSE                        0      12     0.6
    ## 2 TRUE                         8.5     8     0.4

Note also that the effect for the compliers is equal to the
intent-to-treat effect estimate divided by the proportion of compliers.

``` r
fig21.1 %>% 
  summarise(itt = mean(effect),
            proportion_compliers = mean(compliance == "complier")) %>% 
  mutate(effect_on_compliers = itt / proportion_compliers)
```

    ## # A tibble: 1 × 3
    ##     itt proportion_compliers effect_on_compliers
    ##   <dbl>                <dbl>               <dbl>
    ## 1   3.4                  0.4                 8.5

### Deconstructing the complier average causal effect.

The intent-to-treat effect is basically a weighted average of four
different ITT effects–the compliers, the never-takers, the
always-takers, and the defiers. The exclusion criterion sets the
never-takers, the always-takers, and the defiers all to 0. Thus the
complier average causal effect (CACE) is

$$\\text{ITT}\_{c = \\text{complier}} = \\text{CACE} = \\frac{\\text{ITT}}{\\text{Pr}(c = \\text{complier})} = \\frac{\\text{ITT}}{\\text E \\big (T(z = 1) - T(z = 0) \\big)}.$$

#### Violations of ignorability.

Violations of the ignorability assumption could lead to either positive
or negative bias.

#### Violations of the exclusion restriction.

“*Weak instruments*–those that are not strongly predictive of the
treatment–will be highly vulnerable to violations of the exclusion
restriction” (p. 425, *emphasis* in the original).

#### Violations of the monotonicity assumption.

“If the monotonicity assumption is violated, then Pr(*c* = defier) ≠ 0
and consequently the equivalence between Pr(*c* = complier) and
$\\text E (T(1) - T(0))$ is lost” (p. 425).

### Local average treatment effect (LATE) versus intent-to-treat effect (ITT).

> As we have discussed, the instrumental variables strategy here does
> not estimate an overall effect of watching Sesame Street across
> everyone in the study, or even an effect for all those treated. The
> complier average causal effect (CACE) estimate applies only to those
> children whose treatment receipt is dictated by their randomized
> instrument assignment and is a special case of what is commonly called
> a *local average treatment effect* (LATE) by economists. (p. 426,
> *emphasis* in the original)

The ITT or the CACE can be of interest, depending on the research
question. Perhaps it’s best to compute and report both.

### Instrumental variables estimate: Sesame Street.

Here’s the ITT analysis, as presented in the text.

``` r
library(rstanarm)

itt_zt <- 
  stan_glm(data = sesame,
           watched ~ encouraged)
```

Check the summary.

``` r
print(itt_zt)
```

    ## stan_glm
    ##  family:       gaussian [identity]
    ##  formula:      watched ~ encouraged
    ##  observations: 240
    ##  predictors:   2
    ## ------
    ##             Median MAD_SD
    ## (Intercept) 0.5    0.0   
    ## encouraged  0.4    0.1   
    ## 
    ## Auxiliary parameter(s):
    ##       Median MAD_SD
    ## sigma 0.4    0.0   
    ## 
    ## ------
    ## * For help interpreting the printed output see ?print.stanreg
    ## * For info on the priors used see ?prior_summary.stanreg

Note how we used the conventional Gaussian likelihood. Here’s the
**brms** alternative.

``` r
library(brms)

m21.1 <- 
  brm(data = sesame,
      family = gaussian,
      watched ~ encouraged,
      cores = 4,
      seed = 21,
      file = "fits/m21.01")
```

Check the summary.

``` r
print(m21.1)
```

    ##  Family: gaussian 
    ##   Links: mu = identity; sigma = identity 
    ## Formula: watched ~ encouraged 
    ##    Data: sesame (Number of observations: 240) 
    ##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
    ##          total post-warmup draws = 4000
    ## 
    ## Population-Level Effects: 
    ##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## Intercept      0.54      0.04     0.46     0.63 1.00     3407     2686
    ## encouraged     0.36      0.05     0.26     0.47 1.00     3376     2439
    ## 
    ## Family Specific Parameters: 
    ##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## sigma     0.38      0.02     0.35     0.42 1.00     3826     2831
    ## 
    ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
    ## and Tail_ESS are effective sample size measures, and Rhat is the potential
    ## scale reduction factor on split chains (at convergence, Rhat = 1).

The proportion of compliers in the data is .36. We can express the
simple intent-to-treat estimate as

$$
\\begin{align\*}
\\text{postlet}\_i & \\sim \\operatorname{Normal}(\\mu\_i, \\sigma) \\\\
\\mu\_i & = \\beta\_0 + \\beta\_1 \\text{encouraged}\_i.
\\end{align\*}
$$

Fit the model.

``` r
m21.2 <- 
  brm(data = sesame,
      family = gaussian,
      postlet ~ encouraged,
      cores = 4,
      seed = 21,
      file = "fits/m21.02")
```

Check the summary.

``` r
print(m21.2)
```

    ##  Family: gaussian 
    ##   Links: mu = identity; sigma = identity 
    ## Formula: postlet ~ encouraged 
    ##    Data: sesame (Number of observations: 240) 
    ##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
    ##          total post-warmup draws = 4000
    ## 
    ## Population-Level Effects: 
    ##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## Intercept     24.94      1.42    22.12    27.74 1.00     4610     2743
    ## encouraged     2.82      1.78    -0.69     6.26 1.00     5019     2690
    ## 
    ## Family Specific Parameters: 
    ##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## sigma    13.38      0.61    12.26    14.61 1.00     3329     2953
    ## 
    ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
    ## and Tail_ESS are effective sample size measures, and Rhat is the potential
    ## scale reduction factor on split chains (at convergence, Rhat = 1).

Thus, the ITT causal effect is 2.8 95% CI \[-0.7, 6.3\]. Here’s the
point estimate for the CASE.

``` r
fixef(m21.2)["encouraged", 1] / fixef(m21.1)["encouraged", 1]
```

    ## [1] 7.757968

The CACE estimate is much higher than the point estimate for the ITT
effect.

## 21.2 Instrumental variables in a regression framework

If we let *y* be the treatment outcome of interest, *t* be the indicator
of treatment compliance, *z* be the instrumental variable (often
experimental randomization), and *i* index the participants, we can
express the generic instrumental variable framework as

$$
\\begin{align\*}
\\begin{bmatrix} \\color{purple}{t\_i} \\\\ \\color{blue}{y\_i} \\end{bmatrix} & \\sim \\operatorname{Normal} \\left (\\begin{bmatrix} \\color{purple}{\\nu\_i} \\\\ \\color{blue}{\\mu\_i} \\end{bmatrix}, \\begin{bmatrix} \\sigma\_t \\\\ \\sigma\_y \\end{bmatrix} \\right) \\\\
\\color{purple}{\\nu\_i} & = \\gamma\_0 + \\gamma\_1 \\color{red}{z\_i} \\\\
\\color{blue}{\\mu\_i} & = \\beta\_0 + \\beta\_1 \\color{purple}{t\_i},
\\end{align\*}
$$

where the residual standard deviations are presumed orthogonal and
*z*<sub>*i*</sub> is also presumed to be orthogonal to both. This
fulfills the assumption “the instrument only affects the outcome through
its effect on the treatment” (p. 427). Though we use Gaussian likelihood
as a default, we could generalize.

### Identifiability with instrumental variables.

#### Other models.

### Two-stage least squares: Sesame Street.

The conventional *two-stage least squares* (TSLS) approach accomplishes
the estimation difficulties by using the adjusted formula

$$
\\begin{align\*}
\\begin{bmatrix} \\color{purple}{t\_i} \\\\ \\color{blue}{y\_i} \\end{bmatrix} & \\sim \\operatorname{Normal} \\left (\\begin{bmatrix} \\color{purple}{\\nu\_i} \\\\ \\color{blue}{\\mu\_i} \\end{bmatrix}, \\begin{bmatrix} \\sigma\_t \\\\ \\sigma\_y \\end{bmatrix} \\right) \\\\
\\color{purple}{\\nu\_i} & = \\gamma\_0 + \\gamma\_1 \\color{red}{z\_i} \\\\
\\color{blue}{\\mu\_i} & = \\beta\_0 + \\beta\_1 \\color{purple}{\\hat t\_i},
\\end{align\*}
$$

which is identical to the first with the exception that the predictor in
the formula for *μ*<sub>*i*</sub> is now *t̂*<sub>*i*</sub>, the
residuals from the first model. Here’s how to fit the model using the
OLS `lm()` function.

``` r
# stage one
# fit the model on how the experiment influenced compliance
fit_2a <- lm(
  data = sesame,
  watched ~ encouraged) 

# pull the fitted values
sesame <- sesame %>% 
  mutate(watched_hat = fitted(fit_2a))

# stage two
# fit the model on how the fitted compliance values predice the outcome
fit_2b <- lm(
  data = sesame,
  postlet ~ watched_hat)

# summarize
summary(fit_2a)
```

    ## 
    ## Call:
    ## lm(formula = watched ~ encouraged, data = sesame)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -0.90789  0.09211  0.09211  0.09211  0.45455 
    ## 
    ## Coefficients:
    ##             Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)  0.54545    0.04060  13.434  < 2e-16 ***
    ## encouraged   0.36244    0.05102   7.104  1.4e-11 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 0.3809 on 238 degrees of freedom
    ## Multiple R-squared:  0.1749, Adjusted R-squared:  0.1715 
    ## F-statistic: 50.46 on 1 and 238 DF,  p-value: 1.397e-11

``` r
summary(fit_2b)
```

    ## 
    ## Call:
    ## lm(formula = postlet ~ watched_hat, data = sesame)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -24.920 -10.796  -4.796  12.423  38.080 
    ## 
    ## Coefficients:
    ##             Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)   20.593      3.914   5.261 3.19e-07 ***
    ## watched_hat    7.934      4.927   1.610    0.109    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 13.33 on 238 degrees of freedom
    ## Multiple R-squared:  0.01078,    Adjusted R-squared:  0.006623 
    ## F-statistic: 2.593 on 1 and 238 DF,  p-value: 0.1086

The coefficient for `encouraged` in the first model satisfies the
assumption the instrument influences treatment compliance. The
coefficient for `watched_hat` in the second model is the causal effect
of treatment compliance on the outcome, “the effect of watching Sesame
Street on letter recognition for those who would watch if encouraged but
not otherwise (compliers)” (p. 428).

> This second-stage regression does not give the correct standard error,
> however, as we discuss below. (p. 428)

Just to refresh, take a peek at that data structure.

``` r
sesame %>% 
  select(postlet, watched, watched_hat, encouraged) %>% 
  head()
```

    ## # A tibble: 6 × 4
    ##   postlet watched watched_hat encouraged
    ##     <dbl>   <dbl>       <dbl>      <dbl>
    ## 1      30       0       0.908          1
    ## 2      37       1       0.908          1
    ## 3      46       1       0.545          0
    ## 4      14       0       0.545          0
    ## 5      63       1       0.545          0
    ## 6      36       1       0.545          0

### Adjusting for covariates in an instrumental variables framework.

> It turns out that the randomization for this particular experiment
> took place within sites and settings; it is therefore appropriate to
> adjust for these covariates in estimating the treatment effect.
> Additionally, pre-test scores are available that are highly predictive
> of post-test scores. Our preferred model would adjust for all of these
> predictors. (p. 428)

The updated model takes the form

$$ $$

where the covariates are depicted in orange font.

``` r
# stage one
# fit the model on how the experiment influenced compliance
fit_3a <- lm(
  data = sesame,
  watched ~ encouraged + prelet + as.factor(site) + setting) 

# pull the fitted values
sesame <- sesame %>% 
  mutate(watched_hat_3 = fitted(fit_3a))

# stage two
# fit the model on how the fitted compliance values predice the outcome
fit_3b <- lm(
  data = sesame,
  postlet ~ watched_hat_3 + prelet + as.factor(site) + setting)

# summarize
summary(fit_3a)
```

    ## 
    ## Call:
    ## lm(formula = watched ~ encouraged + prelet + as.factor(site) + 
    ##     setting, data = sesame)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1.06980 -0.09759  0.05658  0.26505  0.69673 
    ## 
    ## Coefficients:
    ##                   Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)       0.659730   0.106763   6.179 2.86e-09 ***
    ## encouraged        0.342663   0.050700   6.759 1.12e-10 ***
    ## prelet            0.005052   0.002806   1.801  0.07306 .  
    ## as.factor(site)2  0.029724   0.066378   0.448  0.65472    
    ## as.factor(site)3 -0.114794   0.066189  -1.734  0.08419 .  
    ## as.factor(site)4 -0.343626   0.071372  -4.815 2.66e-06 ***
    ## as.factor(site)5 -0.295021   0.098856  -2.984  0.00315 ** 
    ## setting          -0.053255   0.051646  -1.031  0.30355    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 0.3536 on 232 degrees of freedom
    ## Multiple R-squared:  0.3069, Adjusted R-squared:  0.286 
    ## F-statistic: 14.68 on 7 and 232 DF,  p-value: 8.444e-16

``` r
summary(fit_3b)
```

    ## 
    ## Call:
    ## lm(formula = postlet ~ watched_hat_3 + prelet + as.factor(site) + 
    ##     setting, data = sesame)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -25.308  -6.736  -1.208   6.106  26.652 
    ## 
    ## Coefficients:
    ##                  Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)       1.21922    4.76594   0.256 0.798317    
    ## watched_hat_3    14.03398    4.04500   3.469 0.000622 ***
    ## prelet            0.70000    0.07855   8.912  < 2e-16 ***
    ## as.factor(site)2  8.40258    1.82757   4.598 7.02e-06 ***
    ## as.factor(site)3 -3.94465    1.80821  -2.182 0.030150 *  
    ## as.factor(site)4  0.93894    2.45109   0.383 0.702017    
    ## as.factor(site)5  2.76235    2.89124   0.955 0.340359    
    ## setting           1.59584    1.47939   1.079 0.281833    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 9.667 on 232 degrees of freedom
    ## Multiple R-squared:  0.493,  Adjusted R-squared:  0.4777 
    ## F-statistic: 32.22 on 7 and 232 DF,  p-value: < 2.2e-16

The adjusted model returned a substantially larger causal effect. Yet,

> again, we do not trust this standard error and will discuss later how
> to appropriately adjust it for the two stages of estimation. (p. 429)

### Standard errors for instrumental variables estimates.

Manually adjusting the standard errors is a slog. I’m going to break up
Gelman et al’s code into small bits. First, we extract the predictor
matrix for `fit_3b` save the results with two names.

``` r
X_adj <- X <- model.matrix(fit_3b)

# X_adj and X are the same
str(X_adj)
```

    ##  num [1:240, 1:8] 1 1 1 1 1 1 1 1 1 1 ...
    ##  - attr(*, "dimnames")=List of 2
    ##   ..$ : chr [1:240] "1" "2" "3" "4" ...
    ##   ..$ : chr [1:8] "(Intercept)" "watched_hat_3" "prelet" "as.factor(site)2" ...
    ##  - attr(*, "assign")= int [1:8] 0 1 2 3 3 3 3 4
    ##  - attr(*, "contrasts")=List of 1
    ##   ..$ as.factor(site): chr "contr.treatment"

If you use compact notation *Y* = *X**β* for the outcome model, we just
extracted the full *X* matrix.

Now in the `X_adj` matrix, we switch out the values in the
`watched_hat_3` vector for the original `watched` values from the data.

``` r
X_adj[, "watched_hat_3"] <- sesame$watched
```

Save the dimensions of the *X* matrix.

``` r
n <- nrow(X)
p <- ncol(X)
```

Compute the root mean squared error for both `X` and `X_adj`.

``` r
RMSE1 <- sqrt(sum((sesame$postlet - X     %*% coef(fit_3b))^2) / (n - p)) 
RMSE2 <- sqrt(sum((sesame$postlet - X_adj %*% coef(fit_3b))^2) / (n - p))
```

Now we compare the original standard error for *β*<sub>1</sub> with the
corrected standard error.

``` r
# compute
se_adj <- summary(fit_3b)$coef["watched_hat_3", 2] * RMSE1 / RMSE2

# compare standard errors
summary(fit_3b)$coef["watched_hat_3", 2]  # original (invalid)
```

    ## [1] 4.044999

``` r
se_adj  # adjusted
```

    ## [1] 4.20768

The corrected standard error is a bit larger. Here we compare the
original *t* value with the adjusted *t* value.

``` r
summary(fit_3b)$coef["watched_hat_3", 3]  # original (invalid)
```

    ## [1] 3.469465

``` r
summary(fit_3b)$coef["watched_hat_3", 1] / se_adj  # adjusted
```

    ## [1] 3.335325

### Performing two-stage least squares automatically using brms.

One can use full-luxury Bayesian inference via **brms** to replace the
two-step model with a bivariate model following the form

$$ $$

where the models for *t*<sub>*i*</sub> and *y*<sub>*i*</sub> are
simultaneously fit with the bivariate normal distribution and the new
parameter *ρ* captures any residual covariance between the two
variables. The major advantage of this approach is all the standard
errors will be correct from the outset.

Here’s how to fit the model with **brms**.

``` r
f1 <- bf(watched ~ encour)
f2 <- bf(postlet ~ watched)

m21.3 <-
  brm(data = sesame,
      family = gaussian,
      f1 + f2 + set_rescor(TRUE),
      cores = 4,
      seed = 21,
      file = "fits/m21.03")
```

Check the results.

``` r
print(m21.3, robust = T)  # overall
```

    ##  Family: MV(gaussian, gaussian) 
    ##   Links: mu = identity; sigma = identity
    ##          mu = identity; sigma = identity 
    ## Formula: watched ~ encour 
    ##          postlet ~ watched 
    ##    Data: sesame (Number of observations: 240) 
    ##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
    ##          total post-warmup draws = 4000
    ## 
    ## Population-Level Effects: 
    ##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## watched_Intercept     0.55      0.04     0.47     0.63 1.00     3803     2672
    ## postlet_Intercept    20.16      3.58    13.40    28.01 1.00     2351     2008
    ## watched_encour        0.36      0.05     0.26     0.46 1.00     4052     2520
    ## postlet_watched       8.44      4.58    -1.61    16.88 1.00     2316     1729
    ## 
    ## Family Specific Parameters: 
    ##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## sigma_watched     0.38      0.02     0.35     0.42 1.00     4319     2398
    ## sigma_postlet    12.58      0.66    11.43    14.17 1.00     3279     2083
    ## 
    ## Residual Correlations: 
    ##                         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
    ## rescor(watched,postlet)     0.16      0.15    -0.13     0.44 1.00     2290
    ##                         Tail_ESS
    ## rescor(watched,postlet)     1822
    ## 
    ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
    ## and Tail_ESS are effective sample size measures, and Rhat is the potential
    ## scale reduction factor on split chains (at convergence, Rhat = 1).

``` r
fixef(m21.3, robust = T)["postlet_watched", ]  # focused
```

    ##  Estimate Est.Error      Q2.5     Q97.5 
    ##  8.441641  4.576152 -1.605947 16.883867

Here’s the expanded bivariate normal model.

``` r
f1 <- bf(watched ~ encour + prelet + setting + factor(site))
f2 <- bf(postlet ~ watched + prelet + setting + factor(site))

m21.4 <- 
  brm(data = sesame,
      family = gaussian,
      f1 + f2 + set_rescor(TRUE),
      cores = 4,
      seed = 21,
      file = "fits/m21.04")
```

Check the results.

``` r
print(m21.4, robust = T)  # overall
```

    ##  Family: MV(gaussian, gaussian) 
    ##   Links: mu = identity; sigma = identity
    ##          mu = identity; sigma = identity 
    ## Formula: watched ~ encour + prelet + setting + factor(site) 
    ##          postlet ~ watched + prelet + setting + factor(site) 
    ##    Data: sesame (Number of observations: 240) 
    ##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
    ##          total post-warmup draws = 4000
    ## 
    ## Population-Level Effects: 
    ##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## watched_Intercept       0.67      0.11     0.45     0.88 1.00     3731     2740
    ## postlet_Intercept       1.42      4.76    -8.44    10.34 1.00     1611     2037
    ## watched_encour          0.34      0.05     0.24     0.43 1.00     4905     2949
    ## watched_prelet          0.01      0.00    -0.00     0.01 1.00     6340     3149
    ## watched_setting        -0.06      0.05    -0.16     0.05 1.00     4453     2843
    ## watched_factorsite2     0.03      0.07    -0.10     0.16 1.00     3934     3555
    ## watched_factorsite3    -0.11      0.06    -0.24     0.02 1.00     3444     3081
    ## watched_factorsite4    -0.35      0.07    -0.49    -0.20 1.00     4041     2872
    ## watched_factorsite5    -0.29      0.10    -0.49    -0.11 1.00     3949     3335
    ## postlet_watched        13.84      3.95     6.01    22.28 1.00     1572     2082
    ## postlet_prelet          0.70      0.07     0.55     0.85 1.00     5217     3302
    ## postlet_setting         1.55      1.47    -1.28     4.48 1.00     3131     2594
    ## postlet_factorsite2     8.39      1.81     4.90    11.85 1.00     4752     3453
    ## postlet_factorsite3    -4.00      1.69    -7.43    -0.43 1.00     3744     3144
    ## postlet_factorsite4     0.81      2.37    -3.80     5.83 1.00     2143     2202
    ## postlet_factorsite5     2.61      2.78    -3.04     8.50 1.00     2976     2610
    ## 
    ## Family Specific Parameters: 
    ##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## sigma_watched     0.36      0.02     0.33     0.39 1.00     4952     3032
    ## sigma_postlet     9.42      0.52     8.51    10.66 1.00     2668     2167
    ## 
    ## Residual Correlations: 
    ##                         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
    ## rescor(watched,postlet)    -0.18      0.16    -0.48     0.14 1.00     1583
    ##                         Tail_ESS
    ## rescor(watched,postlet)     2086
    ## 
    ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
    ## and Tail_ESS are effective sample size measures, and Rhat is the potential
    ## scale reduction factor on split chains (at convergence, Rhat = 1).

``` r
fixef(m21.4, robust = T)["postlet_watched", ]  # focused
```

    ##  Estimate Est.Error      Q2.5     Q97.5 
    ## 13.842117  3.948297  6.012331 22.277564

### More than one treatment variable; more than one instrument.

> A single instrument cannot be used to identify more than one treatment
> variable. As a general rule, we need to use at least as many
> instruments as treatment variables in order for all the causal
> estimates to be identifiable. (p. 430)

### Continuous treatment variables or instruments.

> When using two-stage least squares, the models we have discussed can
> easily be extended to accommodate continuous treatment variables and
> instruments, although at the cost of complicating the interpretation
> of the causal effects. (p. 430)

### Have we really avoided the ignorability assumption?

> Broadly speaking, if the ignorability assumption is not highly
> plausible, the expected gains from performing an instrumental
> variables analysis are not likely to outweigh the potential for bias.
> (p. 431)

### Plausibility of exclusion restriction.

### Weak instruments.

> A weak instrument can exacerbate the bias that can result from failure
> to satisfy the ignorability or monotonicity assumptions or the
> exclusion restriction. If a weak instrument leads to a small
> proportion of compliers, this increases the potential for bias if one
> of these assumptions is violated. (p. 431)

### Structural equation models.

## 21.3 Regression discontinuity: known assignment mechanism but no overlap

## Session info

``` r
sessionInfo()
```

    ## R version 4.1.1 (2021-08-10)
    ## Platform: x86_64-apple-darwin17.0 (64-bit)
    ## Running under: macOS Catalina 10.15.7
    ## 
    ## Matrix products: default
    ## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib
    ## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
    ## 
    ## locale:
    ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
    ## 
    ## attached base packages:
    ## [1] stats     graphics  grDevices utils     datasets  methods   base     
    ## 
    ## other attached packages:
    ##  [1] brms_2.16.2     rstanarm_2.21.1 Rcpp_1.0.7      forcats_0.5.1  
    ##  [5] stringr_1.4.0   dplyr_1.0.7     purrr_0.3.4     readr_2.0.1    
    ##  [9] tidyr_1.1.3     tibble_3.1.5    ggplot2_3.3.5   tidyverse_1.3.1
    ## 
    ## loaded via a namespace (and not attached):
    ##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
    ##   [4] igraph_1.2.6         splines_4.1.1        crosstalk_1.1.1     
    ##   [7] TH.data_1.0-10       rstantools_2.1.1     inline_0.3.19       
    ##  [10] digest_0.6.28        htmltools_0.5.2      rsconnect_0.8.24    
    ##  [13] fansi_0.5.0          magrittr_2.0.1       checkmate_2.0.0     
    ##  [16] tzdb_0.1.2           modelr_0.1.8         RcppParallel_5.1.4  
    ##  [19] matrixStats_0.60.1   vroom_1.5.4          sandwich_3.0-1      
    ##  [22] xts_0.12.1           prettyunits_1.1.1    colorspace_2.0-2    
    ##  [25] rvest_1.0.1          haven_2.4.3          xfun_0.25           
    ##  [28] callr_3.7.0          crayon_1.4.1         jsonlite_1.7.2      
    ##  [31] lme4_1.1-27.1        survival_3.2-11      zoo_1.8-9           
    ##  [34] glue_1.4.2           gtable_0.3.0         emmeans_1.6.3       
    ##  [37] V8_3.4.2             distributional_0.2.2 pkgbuild_1.2.0      
    ##  [40] rstan_2.26.3         abind_1.4-5          scales_1.1.1        
    ##  [43] mvtnorm_1.1-2        DBI_1.1.1            miniUI_0.1.1.1      
    ##  [46] xtable_1.8-4         bit_4.0.4            stats4_4.1.1        
    ##  [49] StanHeaders_2.26.3   DT_0.19              htmlwidgets_1.5.3   
    ##  [52] httr_1.4.2           threejs_0.3.3        posterior_1.0.1     
    ##  [55] ellipsis_0.3.2       pkgconfig_2.0.3      loo_2.4.1           
    ##  [58] farver_2.1.0         dbplyr_2.1.1         utf8_1.2.2          
    ##  [61] tidyselect_1.1.1     rlang_0.4.11         reshape2_1.4.4      
    ##  [64] later_1.3.0          munsell_0.5.0        cellranger_1.1.0    
    ##  [67] tools_4.1.1          cli_3.0.1            generics_0.1.0      
    ##  [70] broom_0.7.9          ggridges_0.5.3       evaluate_0.14       
    ##  [73] fastmap_1.1.0        yaml_2.2.1           processx_3.5.2      
    ##  [76] knitr_1.33           bit64_4.0.5          fs_1.5.0            
    ##  [79] nlme_3.1-152         mime_0.11            projpred_2.0.2      
    ##  [82] xml2_1.3.2           compiler_4.1.1       bayesplot_1.8.1     
    ##  [85] shinythemes_1.2.0    rstudioapi_0.13      curl_4.3.2          
    ##  [88] gamm4_0.2-6          reprex_2.0.1         stringi_1.7.4       
    ##  [91] ps_1.6.0             Brobdingnag_1.2-6    lattice_0.20-44     
    ##  [94] Matrix_1.3-4         nloptr_1.2.2.2       markdown_1.1        
    ##  [97] shinyjs_2.0.0        tensorA_0.36.2       vctrs_0.3.8         
    ## [100] pillar_1.6.3         lifecycle_1.0.1      bridgesampling_1.1-2
    ## [103] estimability_1.3     httpuv_1.6.2         R6_2.5.1            
    ## [106] promises_1.2.0.1     gridExtra_2.3        codetools_0.2-18    
    ## [109] boot_1.3-28          colourpicker_1.1.0   MASS_7.3-54         
    ## [112] gtools_3.9.2         assertthat_0.2.1     withr_2.4.2         
    ## [115] shinystan_2.5.0      multcomp_1.4-17      mgcv_1.8-36         
    ## [118] parallel_4.1.1       hms_1.1.0            grid_4.1.1          
    ## [121] coda_0.19-4          minqa_1.2.4          rmarkdown_2.10      
    ## [124] shiny_1.6.0          lubridate_1.7.10     base64enc_0.1-3     
    ## [127] dygraphs_1.1.1.6
