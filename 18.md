Chapter 18: Causal inference and randomized experiments
================
A Solomon Kurz
2020-12-31

# Causal inference and randomized experiments

> This section of the book considers *causal inference*, which concerns
> what *would happen* to an outcome \(y\) as a result of a treatment,
> intervention, or exposure \(z\), given pre-treatment information
> \(x\). This chapter introduces the notation and ideas of causal
> inference in the context of randomized experiments, which allow clean
> inference for average causal effects and serve as a starting point for
> understanding the tools and challenges of causal estimation. (p. 339,
> *emphasis* in the original)

## 18.1 Basics of causal inference

> For most statisticians, ourselves included, causal effects are
> conceptualized as a comparison between different potential outcomes of
> what might have occurred under different scenarios. This comparison
> could be between a factual state (what did happen) and one or more
> counterfactual states (representing what might have happened), or it
> could be a comparison among various counterfactuals. (p. 339)

### 18.1.1 Running example.

  - 4 friends are in a treatment condition where they 3 grams of fish
    oil supplement daily for a year
  - another 4 friends are in the control condition where they do not
    take the fish oil supplement for that same year
  - at the end of the year, you take systolic blood pressure for all 8
    friends
  - 60 mmHg and higher are considered *high blood pressure*
  - you presume everyone complied with the study parameters

### 18.1.2 Potential outcomes, counterfactuals, and causal effects.

  - \(z = 0\) denotes “no fish oil supplements ingested”
  - \(z = 1\) denotes “3 grams per day of fish oil supplements ingested”

The *potential outcomes* are:

  - \(y_i^0\): the blood pressure that would result if the person had no
    supplement
  - \(y_i^1\): the blood pressure that would result if the person had
    received the prescribed supplement

The *factual state* is what actually occurred for the participants; it
is observed. The *counterfactual state* is what we infer would have
occurred had the participants been in different conditions; it is not
observed.

The causal effect of the supplement is \(\tau_i = y_i^1 - y_i^0\).

### 18.1.3 The fundamental problem of causal inference.

“The problem inherent in determining the effect for any given
individual, however, is that we can never observe both potential
outcomes \(y_i^0\) *and* \(y_i^1\)” (p. 340).

Here’s the data for the table in Figure 18.1.

``` r
library(tidyverse)

d <-
  tibble(i         = c("Audrey", "Anna", "Bob", "Bill", "Caitlin", "Cara", "Dave", "Doug"),
         female    = c(1, 1, 0, 0, 1, 1, 0, 0),
         age       = rep(4:7 * 10, each = 2),
         treatment = rep(0:1, each = 4),
         y0        = c(140, 140, 150, 150, NA, NA, NA, NA),
         y1        = c(NA, NA, NA, NA, 155, 155, 160, 160),
         y         = ifelse(is.na(y1), y0, y1))

d
```

    ## # A tibble: 8 x 7
    ##   i       female   age treatment    y0    y1     y
    ##   <chr>    <dbl> <dbl>     <int> <dbl> <dbl> <dbl>
    ## 1 Audrey       1    40         0   140    NA   140
    ## 2 Anna         1    40         0   140    NA   140
    ## 3 Bob          0    50         0   150    NA   150
    ## 4 Bill         0    50         0   150    NA   150
    ## 5 Caitlin      1    60         1    NA   155   155
    ## 6 Cara         1    60         1    NA   155   155
    ## 7 Dave         0    70         1    NA   160   160
    ## 8 Doug         0    70         1    NA   160   160

“If treatments are randomly assigned, we can estimate an average causal
effect, but even then this will not tell us about the effect on any
given person” (p. 340).

### 18.1.4 Close substitutes.

Because of potential history effects, you cannot simply substitute
someone’s pre-treatment measure of the criterion for what their post
measure would have been had they not been in the treatment condition.
Say we’re talking about the \(j\)th participant. Maybe
\(y_j^\text{before} = y_j^0\), or maybe
\(y_j^\text{before} \neq y_j^0\). Even if you do some kind of ABA
design, this is only valid if the treatment in B has short-term effects.
Sometimes you can overcome this with a *washout period*, ABCA.
Randomizing large numbers of people to treatment conditions helps, some.

### 18.1.5 More than two treatment levels, continuous treatments, and multiple treatment factors.

> Going beyond a simple treatment-and-control setting, multiple
> treatment effects can be defined relative to a baseline level. With
> random assignment, this simply follows general principles of
> regression modeling….
> 
> With several discrete treatments that are unordered, as in a
> comparison of three different sorts of psychotherapy, we can move to
> multilevel modeling, with the group index indicating the treatment
> assigned to each unit, and a second-level model on the group
> coefficients, or treatment effects.
> 
> Additionally, multiple treatments can be administered in combination.
> For instance, depressed individuals could be randomly assigned to
> receive nothing, drugs, counseling sessions, or both drugs and
> counseling sessions. These combinations could be modeled as two
> treatments and their interaction or as four distinct treatments.
> (p. 342)

## 18.2 Average causal effects

“In experiments in which only one treatment is applied to each
individual, it will not be possible to estimate individual-level causal
effects, \(y_i^1 - y_i^0\)” (p. 342).

To make the table in Figure 18.2, update our `d` data.

``` r
d %>% 
  mutate(y0 = rep(14:17 * 10, each = 2),
         y1 = rep(c(27:28, 31:32) * 5, each = 2))
```

    ## # A tibble: 8 x 7
    ##   i       female   age treatment    y0    y1     y
    ##   <chr>    <dbl> <dbl>     <int> <dbl> <dbl> <dbl>
    ## 1 Audrey       1    40         0   140   135   140
    ## 2 Anna         1    40         0   140   135   140
    ## 3 Bob          0    50         0   150   140   150
    ## 4 Bill         0    50         0   150   140   150
    ## 5 Caitlin      1    60         1   160   155   155
    ## 6 Cara         1    60         1   160   155   155
    ## 7 Dave         0    70         1   170   160   160
    ## 8 Doug         0    70         1   170   160   160

If we actually had this information, we could compute
\(\tau_i = y_i^1 - y_i^0\), the individual treatment effect for all
\(i\) cases.

### 18.2.1 Sample average treatment effect (SATE).

Here’s the average treatment effect, if we had all the data.

``` r
d %>% 
  mutate(y0 = rep(14:17 * 10, each = 2),
         y1 = rep(c(27:28, 31:32) * 5, each = 2)) %>% 
  mutate(y = y1 - y0) %>% 
  summarise(mean_tx_effect = mean(y))
```

    ## # A tibble: 1 x 1
    ##   mean_tx_effect
    ##            <dbl>
    ## 1           -7.5

You call this the sample average treatment effect (SATE), which may be
defined as

\[\tau_\text{SATE} = \frac{1}{n} \sum_{i = 1}^n (y_i^1 = y_i^0).\]

### 18.2.2 Conditional average treatment effect (CATE).

The average treatment effect for a subset (e.g., based on race or sex)
is the *conditional average treatment effect* (CATE). Here’s the CATE by
`female`.

``` r
d %>% 
  mutate(y0 = rep(14:17 * 10, each = 2),
         y1 = rep(c(27:28, 31:32) * 5, each = 2)) %>% 
  mutate(y = y1 - y0) %>% 
  group_by(female) %>% 
  summarise(mean_tx_effect = mean(y))
```

    ## # A tibble: 2 x 2
    ##   female mean_tx_effect
    ##    <dbl>          <dbl>
    ## 1      0            -10
    ## 2      1             -5

### 18.2.3 Population average treatment effect (PATE).

Going beyond the sample, the *population average treatment effect*
(PATE) may be defined as

\[\tau_\text{PATE} = \frac{1}{N} \sum_{i = 1}^N (y_i^1 = y_i^0).\]

From the PATE perspective, we now have missing data for (a) the
counterfactual values within our sample and (b) all potential outcomes
for those within the population but not in our sample.

### 18.2.4 Problems with self-selection into treatment groups.

You can run into problems when experimental groups are not balances on
all relevant variables. For example, our two `treatment` differ
substantially by their average `age`.

``` r
d %>% 
  group_by(treatment) %>% 
  summarise(mean_age = mean(age))
```

    ## # A tibble: 2 x 2
    ##   treatment mean_age
    ##       <int>    <dbl>
    ## 1         0       45
    ## 2         1       65

### 18.2.5 Using design and analysis to address imbalance and lack of overlap between treatment and control groups.

> In practice, we can never ensure that treatment and control groups are
> balanced on all relevant pre-treatment characteristics. However, there
> are statistical approaches that may bring us closer. At the design
> stage, we can use *randomization* to ensure that treatment and control
> groups are balanced in expectation, and we can use *blocking* to
> reduce the variation in any imbalance. At the analysis stage, we can
> *adjust* for pre-treatment variables to correct for differences
> between the two groups to reduce bias in our estimate of the sample
> average treatment effect. We can further adjust for differences
> between sample and population if our goal is to estimate the
> population average treatment effect. (p. 344, *emphasis* in the
> original)

## 18.3 Randomized experiments

We can randomly assign using the `sample()` function.

``` r
set.seed(18)

sample(c(0, 0, 0, 0, 1, 1, 1, 1), size = 8, replace = F)
```

    ## [1] 0 0 0 1 1 1 1 0

Here’s a more compact way to achieve the same kind of thing.

``` r
set.seed(18)

sample(0:1, size = 8, replace = T)
```

    ## [1] 1 1 0 1 1 1 1 0

### 18.3.1 Completely randomized experiments.

“In a *completely randomized experiment*, the probability of being
assigned to the treatment is the same for each unit in the sample”
(p. 345, *emphasis* in the original).

#### 18.3.1.1 An idealized outcome from a completely randomized experiment.

Here’s our version of the table in Figure 18.3, if `treatment` condition
was assigned sequentially to every other participant.

``` r
d %>% 
  mutate(treatment = rep(0:1, times = 4)) %>% 
  mutate(y0 = rep(14:17 * 10, each = 2),
         y1 = rep(c(27:28, 31:32) * 5, each = 2)) %>% 
  mutate(y = ifelse(treatment == 0, y0, y1))
```

    ## # A tibble: 8 x 7
    ##   i       female   age treatment    y0    y1     y
    ##   <chr>    <dbl> <dbl>     <int> <dbl> <dbl> <dbl>
    ## 1 Audrey       1    40         0   140   135   140
    ## 2 Anna         1    40         1   140   135   135
    ## 3 Bob          0    50         0   150   140   150
    ## 4 Bill         0    50         1   150   140   140
    ## 5 Caitlin      1    60         0   160   155   160
    ## 6 Cara         1    60         1   160   155   155
    ## 7 Dave         0    70         0   170   160   170
    ## 8 Doug         0    70         1   170   160   160

Granted the values, above, here would be our estimate of \(\tau\).

``` r
d %>% 
  mutate(treatment = rep(0:1, times = 4)) %>% 
  mutate(y0 = rep(14:17 * 10, each = 2),
         y1 = rep(c(27:28, 31:32) * 5, each = 2)) %>% 
  mutate(y = ifelse(treatment == 0, y0, y1)) %>% 
  group_by(treatment) %>% 
  summarise(y = mean(y)) %>% 
  pivot_wider(names_from = treatment, values_from = y) %>% 
  mutate(tau = `1` - `0`)
```

    ## # A tibble: 1 x 3
    ##     `0`   `1`   tau
    ##   <dbl> <dbl> <dbl>
    ## 1   155  148.  -7.5

We could also estimate this with the regression model
\(y_i = a + \tau z_i + \text{error}_i\).

#### 18.3.1.2 A less idealized randomized result.

Here we make the table of Figure 18.4, where randomization was
imperfect.

``` r
d %>% 
  mutate(treatment = rep(c(1, 0, 1), times = c(3, 4, 1))) %>% 
  mutate(y0 = rep(14:17 * 10, each = 2),
         y1 = rep(c(27:28, 31:32) * 5, each = 2)) %>% 
  mutate(y = ifelse(treatment == 0, y0, y1))
```

    ## # A tibble: 8 x 7
    ##   i       female   age treatment    y0    y1     y
    ##   <chr>    <dbl> <dbl>     <dbl> <dbl> <dbl> <dbl>
    ## 1 Audrey       1    40         1   140   135   135
    ## 2 Anna         1    40         1   140   135   135
    ## 3 Bob          0    50         1   150   140   140
    ## 4 Bill         0    50         0   150   140   150
    ## 5 Caitlin      1    60         0   160   155   160
    ## 6 Cara         1    60         0   160   155   160
    ## 7 Dave         0    70         0   170   160   170
    ## 8 Doug         0    70         1   170   160   160

Now `treatment` groups still differ notably by `age`.

``` r
d %>% 
  mutate(treatment = rep(c(1, 0, 1), times = c(3, 4, 1))) %>% 
  mutate(y0 = rep(14:17 * 10, each = 2),
         y1 = rep(c(27:28, 31:32) * 5, each = 2)) %>% 
  mutate(y = ifelse(treatment == 0, y0, y1)) %>% 
  group_by(treatment) %>% 
  summarise(mean_age = mean(age))
```

    ## # A tibble: 2 x 2
    ##   treatment mean_age
    ##       <dbl>    <dbl>
    ## 1         0       60
    ## 2         1       50

Granted the values, above, our estimate of \(\tau\) comes out biased.

``` r
d %>% 
  mutate(treatment = rep(c(1, 0, 1), times = c(3, 4, 1))) %>% 
  mutate(y0 = rep(14:17 * 10, each = 2),
         y1 = rep(c(27:28, 31:32) * 5, each = 2)) %>% 
  mutate(y = ifelse(treatment == 0, y0, y1)) %>% 
  group_by(treatment) %>% 
  summarise(y = mean(y)) %>% 
  pivot_wider(names_from = treatment, values_from = y) %>% 
  mutate(tau = `1` - `0`)
```

    ## # A tibble: 1 x 3
    ##     `0`   `1`   tau
    ##   <dbl> <dbl> <dbl>
    ## 1   160  142. -17.5

## 18.4 Sampling distributions, randomization distributions, and bias in estimation

> When considering the population average treatment effect, we can
> conceptualize drawing a random sample of size \(n_1\) from a
> population to receive the treatment, drawing a random sample of size
> \(n_0\) from the same population to receive the control, and taking
> the difference between the average response in each as an estimate of
> the population average treatment effect. If this were done over and
> over, the estimates would form a sampling distribution for this
> estimate. For the estimate to be unbiased, we would need the mean of
> this sampling distribution to be centered on the true
> \(\tau_\text{PATE}\). A stricter criterion that would also lead to an
> unbiased treatment effect estimate would require the sampling
> distributions of the mean of \(y\) for the control and treated units
> to be centered on the population average of \(y_0\) and the population
> average of \(y_1\), respectively.
> 
> Even if an estimate is unbiased, this does not guarantee that the
> estimate from any particular random assignment will be close to the
> true value of the estimand, particularly when the sample is small.
> (pp. 346–347)

## 18.5 Using additional information in experimental design

“In many experimental settings, pre-treatment information is available
that can be used in the experimental design to yield more precise and
less biased estimates of treatment effects” (p. 347). The reason the
`treatment` assignment from the data in Figure 18.3 yielded an unbiased
estimate is because of how every two rows (e.g., 1 and 2, 3 and 4, …)
were effectively grouped by `age`. By assigning `treatment` to every
other row, it was effectively randomized by *blocks*.

### 18.5.1 Randomized blocks experiments.

Here are the data for the expanded experiment of Figure 18.5, where
`treatment` is not equal across `age` blocks.

``` r
d <-
  tibble(i         = c("Audrey", "Abigail", "Arielle", "Anna", "Bob", "Bill", "Burt", "Brad", "Caitlin", "Cara", "Cassie", "Cindy", "Dave", "Doug", "Dylan", "Derik"),
         female    = rep(c(0, 1, 0, 1), each = 4),
         age       = rep(4:7 * 10, each = 4),
         treatment = rep(c(0, 1, 0, 1, 0, 1, 0, 1), times = c(3, 1, 3, 1, 1, 3, 1, 3)),
         y0        = rep(14:17 * 10, each = 4),
         y1        = rep(c(27:28, 31:32) * 5, each = 4)) %>% 
  mutate(y = ifelse(treatment == 0, y0, y1))

d
```

    ## # A tibble: 16 x 7
    ##    i       female   age treatment    y0    y1     y
    ##    <chr>    <dbl> <dbl>     <dbl> <dbl> <dbl> <dbl>
    ##  1 Audrey       0    40         0   140   135   140
    ##  2 Abigail      0    40         0   140   135   140
    ##  3 Arielle      0    40         0   140   135   140
    ##  4 Anna         0    40         1   140   135   135
    ##  5 Bob          1    50         0   150   140   150
    ##  6 Bill         1    50         0   150   140   150
    ##  7 Burt         1    50         0   150   140   150
    ##  8 Brad         1    50         1   150   140   140
    ##  9 Caitlin      0    60         0   160   155   160
    ## 10 Cara         0    60         1   160   155   155
    ## 11 Cassie       0    60         1   160   155   155
    ## 12 Cindy        0    60         1   160   155   155
    ## 13 Dave         1    70         0   170   160   170
    ## 14 Doug         1    70         1   170   160   160
    ## 15 Dylan        1    70         1   170   160   160
    ## 16 Derik        1    70         1   170   160   160

Now the overall sample estimate for \(\tau\) is biased.

``` r
d %>% 
  group_by(treatment) %>% 
  summarise(y = mean(y)) %>% 
  pivot_wider(names_from = treatment, values_from = y) %>% 
  mutate(tau = `1` - `0`)
```

    ## # A tibble: 1 x 3
    ##     `0`   `1`   tau
    ##   <dbl> <dbl> <dbl>
    ## 1   150  152.   2.5

Here’s what happens if we compute \(\hat \tau_j\) within each of the
\(j\) `age` block.

``` r
d %>% 
  group_by(age, treatment) %>% 
  summarise(y = mean(y)) %>% 
  pivot_wider(names_from = treatment, values_from = y) %>% 
  mutate(tau_j = `1` - `0`)
```

    ## # A tibble: 4 x 4
    ## # Groups:   age [4]
    ##     age   `0`   `1` tau_j
    ##   <dbl> <dbl> <dbl> <dbl>
    ## 1    40   140   135    -5
    ## 2    50   150   140   -10
    ## 3    60   160   155    -5
    ## 4    70   170   160   -10

If we take the average of the \(\hat \tau_j\)’s, we’ll get an unbiased
estimate.

``` r
d %>% 
  group_by(age, treatment) %>% 
  summarise(y = mean(y)) %>% 
  pivot_wider(names_from = treatment, values_from = y) %>% 
  mutate(tau_j = `1` - `0`) %>% 
  ungroup() %>% 
  summarise(tau = mean(tau_j))
```

    ## # A tibble: 1 x 1
    ##     tau
    ##   <dbl>
    ## 1  -7.5

You can also get an unbiased estimate by fitting the model

\[y_i = a + \tau_\text{RB} z_i + \gamma_1 b_{1i} + \gamma_2 b_{2i} + \gamma_3 b_{3i} + \text{error}_i,\]

where \(\tau_\text{RB}\) is the focal parameter, the treatment effect
given a random block design. The \(a\) parameter is the typical
intercept, and the three \(\gamma\) parameters denote the deviations
based on the block dummies. Here’s how to fit the model with **brms**.

``` r
library(brms)

m18.1 <-
  brm(data = d,
      y ~ 1 + treatment + factor(age),
      seed = 18,
      file = "fits/m18.01")
```

Check the model summary.

``` r
print(m18.1)
```

    ##  Family: gaussian 
    ##   Links: mu = identity; sigma = identity 
    ## Formula: y ~ 1 + treatment + factor(age) 
    ##    Data: d (Number of observations: 16) 
    ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
    ##          total post-warmup samples = 4000
    ## 
    ## Population-Level Effects: 
    ##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## Intercept     140.61      0.78   139.05   142.18 1.00     2795     2312
    ## treatment      -7.51      0.87    -9.25    -5.84 1.00     3221     2645
    ## factorage50     8.77      1.08     6.58    10.93 1.00     2895     2141
    ## factorage60    21.27      1.15    19.05    23.62 1.00     2162     2558
    ## factorage70    27.52      1.14    25.23    29.73 1.00     2497     2421
    ## 
    ## Family Specific Parameters: 
    ##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## sigma     1.47      0.38     0.96     2.38 1.00     1752     2013
    ## 
    ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
    ## and Tail_ESS are effective sample size measures, and Rhat is the potential
    ## scale reduction factor on split chains (at convergence, Rhat = 1).

The parameter in the `treatment` line is our causal effect,
\(\tau_\text{RB}\).

#### 18.5.1.1 Motivations for randomization in blocks.

#### 18.5.1.2 Defining blocks in practice.

> How do we choose blocks when our goal is to increase statistical
> efficiency? The goal when creating blocks is to minimize the variation
> of each type of potential outcome, \(y^0\) and \(y^1\), within the
> block. (p. 349)

### 18.5.2 Matched pairs experiments.

Matched pairs randomized experiments are special cases of a randomized
block design where each matched pair is a 2-unit block, such as in the
case of twins. Within each pair, you randomize one to each of the two
levels of treatment. This can make more efficient estimation due to the
high homogeneity within blocks.

### 18.5.3 Group or cluster-randomized experiments.

> Sometimes it is difficult or problematic to randomize treatment
> assignments to individual units, and so researchers instead randomize
> groups or clusters to receive the treatment. This design choice might
> be motivated by how a treatment is implemented. For instance, group
> therapy strategies typically are implemented at the group level–that
> is, with every person in a group receiving the same treatment.
> (p. 349)

### 18.5.4 Using design-relevant information in subsequent data analysis.

Though blocking is sometimes more efficient than pure randomization,
cluster randomizing is often less efficient.

> It is best to include pre-treatment information in the design if this
> is feasible. But in any case, whether or not this information is
> accounted for in the design, it should be included in the analysis by
> including relevant pre-treatment information as predictors. (p. 350)

## 18.6 Properties, assumptions, and limitations of randomized experiments

> When the design yields no average differences between groups, a simple
> difference in means will yield an unbiased estimate of the sample
> average treatment effect, and a regression on treatment indicator,
> also adjusting for pre-treatment predictors, will also be unbiased but
> can do even better by reducing variance. (p. 350)

### 18.6.1 Ignorability.

#### 18.6.1.1 Completely randomized experiments.

“In a completely randomized design, the treatment assignment is a random
variable that is independent of the potential outcomes” (p. 350). This
implies that there will be no difference, on average, in potential
outcomes across repeated randomizations, a condition called
*ignorability*.

#### 18.6.1.2 Randomized blocks experiments.

“When we randomize within blocks, the independence between potential
outcomes and the treatment variable holds only conditional on block
membership, \(w\)” (p. 351).

#### 18.6.1.3 Matched pairs experiments.

> The most straightforward approach to treatment effect estimation that
> accounts for the matched pairs design is to calculate pair-specific
> differences in outcomes, \(d_j = y_j^T - y_j^C\) (where \(y_j^T\) is
> the outcome of the treated unit in pair \(j\) and \(y_j^C\) is the
> outcome of the control unit in pair \(j\)), and then calculate an
> average of those \(K\) differences,
> \(\overline d = \frac{1}{K} \sum_{k=1}^K d_j\). Including a predictor
> for each pair makes such models noisy to estimate using simple
> regression; data from such designs can often be more efficiently fit
> using multilevel models. (p. 352)

### 18.6.2 Efficiency.

> The more similar the potential outcomes are across treatment groups,
> the *closer* our estimate will be on average to the value of the
> estimand. Said another way, the more similar are the units being
> compared across treatment groups, the smaller the variance of the
> randomization or sampling distribution will be. (p. 352, *emphasis* in
> the original)

#### 18.6.2.1 Randomized blocks experiments.

> Ideally, the randomized block experiment creates subgroups (blocks)
> within which the \(y_i^0\)’s are more similar to each other and the
> \(y_i^1\)’s are more similar to each other across treatment groups.
> This makes it possible to get sharper estimates of block-specific
> treatment effects, which can then be combined using a weighted average
> into an estimate of the average treatment effect across the entire
> experimental sample or population. (p. 352)

#### 18.6.2.2 Increasing precision by adjusting for pre-treatment variables.

Once again, here are the data from Figure 18.3.

``` r
d <-
  tibble(i         = c("Audrey", "Anna", "Bob", "Bill", "Caitlin", "Cara", "Dave", "Doug"),
         female    = c(1, 1, 0, 0, 1, 1, 0, 0),
         age       = rep(4:7 * 10, each = 2),
         treatment = rep(0:1, times = 4),
         y0        = rep(14:17 * 10, each = 2),
         y1        = rep(c(27:28, 31:32) * 5, each = 2)) %>% 
  mutate(y = ifelse(treatment == 0, y0, y1))

d
```

    ## # A tibble: 8 x 7
    ##   i       female   age treatment    y0    y1     y
    ##   <chr>    <dbl> <dbl>     <int> <dbl> <dbl> <dbl>
    ## 1 Audrey       1    40         0   140   135   140
    ## 2 Anna         1    40         1   140   135   135
    ## 3 Bob          0    50         0   150   140   150
    ## 4 Bill         0    50         1   150   140   140
    ## 5 Caitlin      1    60         0   160   155   160
    ## 6 Cara         1    60         1   160   155   155
    ## 7 Dave         0    70         0   170   160   170
    ## 8 Doug         0    70         1   170   160   160

On page 352, the authors commented on the standard errors for the models

\[
\begin{align*}
y_i & \sim \operatorname N(\mu_i, \sigma) \\
\mu_i & = a + \tau\ \text{treatment}_i
\end{align*}
\]

and

\[
\begin{align*}
y_i & \sim \operatorname N(\mu_i, \sigma) \\
\mu_i & = a + \tau\ \text{treatment}_i + b_1 \text{female}_i + b_2 \text{age}_i.
\end{align*}
\]

Though they didn’t show example code fitting these in the text, here we
fit them with **brms**.

``` r
m18.2 <-
  brm(data = d,
      y ~ 1 + treatment,
      seed = 18,
      file = "fits/m18.02")

m18.3 <-
  brm(data = d,
      y ~ 1 + treatment + female + age,
      seed = 18,
      file = "fits/m18.03")
```

Check the model summary.

``` r
print(m18.2, robust = T)
```

    ##  Family: gaussian 
    ##   Links: mu = identity; sigma = identity 
    ## Formula: y ~ 1 + treatment 
    ##    Data: d (Number of observations: 8) 
    ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
    ##          total post-warmup samples = 4000
    ## 
    ## Population-Level Effects: 
    ##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## Intercept   155.19      6.56   141.54   169.37 1.00     2741     2299
    ## treatment    -7.53      9.57   -27.61    13.16 1.00     2699     2122
    ## 
    ## Family Specific Parameters: 
    ##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## sigma    13.08      3.51     8.22    24.93 1.00     2059     2048
    ## 
    ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
    ## and Tail_ESS are effective sample size measures, and Rhat is the potential
    ## scale reduction factor on split chains (at convergence, Rhat = 1).

``` r
print(m18.3, robust = T)
```

    ##  Family: gaussian 
    ##   Links: mu = identity; sigma = identity 
    ## Formula: y ~ 1 + treatment + female + age 
    ##    Data: d (Number of observations: 8) 
    ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
    ##          total post-warmup samples = 4000
    ## 
    ## Population-Level Effects: 
    ##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## Intercept    98.54      5.03    84.90   111.77 1.00     2628     1781
    ## treatment    -7.45      1.61   -11.73    -3.01 1.01     2820     1653
    ## female        2.56      1.84    -2.38     7.65 1.00     2833     1551
    ## age           1.00      0.08     0.80     1.22 1.00     2809     1964
    ## 
    ## Family Specific Parameters: 
    ##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    ## sigma     2.26      0.94     1.12     6.83 1.00      928     1173
    ## 
    ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
    ## and Tail_ESS are effective sample size measures, and Rhat is the potential
    ## scale reduction factor on split chains (at convergence, Rhat = 1).

The posterior mad sd values for our \(\tau\) parameters are a little
larger than those listed in the text. Let’s compare what we get when
fitting the models with OLS.

``` r
lm(data = d,
   y ~ 1 + treatment) %>% 
  summary()
```

    ## 
    ## Call:
    ## lm(formula = y ~ 1 + treatment, data = d)
    ## 
    ## Residuals:
    ##    Min     1Q Median     3Q    Max 
    ## -15.00  -8.75   0.00   8.75  15.00 
    ## 
    ## Coefficients:
    ##             Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)  155.000      6.208  24.967 2.72e-07 ***
    ## treatment     -7.500      8.780  -0.854    0.426    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 12.42 on 6 degrees of freedom
    ## Multiple R-squared:  0.1084, Adjusted R-squared:  -0.04016 
    ## F-statistic: 0.7297 on 1 and 6 DF,  p-value: 0.4258

``` r
lm(data = d,
   y ~ 1 + treatment + female + age) %>% 
  summary()
```

    ## 
    ## Call:
    ## lm(formula = y ~ 1 + treatment + female + age, data = d)
    ## 
    ## Residuals:
    ##     1     2     3     4     5     6     7     8 
    ## -1.25  1.25  1.25 -1.25 -1.25  1.25  1.25 -1.25 
    ## 
    ## Coefficients:
    ##             Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)  98.7500     3.9031  25.300 1.45e-05 ***
    ## treatment    -7.5000     1.2500  -6.000  0.00388 ** 
    ## female        2.5000     1.3975   1.789  0.14815    
    ## age           1.0000     0.0625  16.000 8.92e-05 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 1.768 on 4 degrees of freedom
    ## Multiple R-squared:  0.988,  Adjusted R-squared:  0.9789 
    ## F-statistic: 109.3 on 3 and 4 DF,  p-value: 0.0002711

This time, the standard errors do match those in the text. *What gives?*
With only eight data points, the likelihoods are very weak and our
**brms** models are using default flat priors for the parameters of
`class = b`. Yet across all four models, the point estimate for \(\tau\)
hovered consistently around the true value -7.5.

### 18.6.3 Stable unit treatment value assumption (SUTVA): no interference among units and no hidden versions of the treatment.

The *stable unit treatment value assumption* (SUTVA) is “the potential
outcome for unit \(i\) depends only on the treatment” (p. 353), which
means the treatment status of a given participant does not effect the
status of other participants. It also means that the kind or intensity
of treatment is stable across time and participants.

### 18.6.4 External validity: Difficulty of extrapolating to new individuals and situations.

“To the extent that the sample is not representative of the population,
and that the environment in the study does not reflect the outside
world, we say that the design lacks *external validity*” (p. 353,
*emphasis* in the original).

### 18.6.5 How the experiment affects the participants.

### 18.6.6 Missing data and noncompliance.

## Session info

``` r
sessionInfo()
```

    ## R version 4.0.3 (2020-10-10)
    ## Platform: x86_64-apple-darwin17.0 (64-bit)
    ## Running under: macOS Catalina 10.15.7
    ## 
    ## Matrix products: default
    ## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
    ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
    ## 
    ## locale:
    ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
    ## 
    ## attached base packages:
    ## [1] stats     graphics  grDevices utils     datasets  methods   base     
    ## 
    ## other attached packages:
    ##  [1] brms_2.14.4     Rcpp_1.0.5      forcats_0.5.0   stringr_1.4.0  
    ##  [5] dplyr_1.0.2     purrr_0.3.4     readr_1.4.0     tidyr_1.1.2    
    ##  [9] tibble_3.0.4    ggplot2_3.3.2   tidyverse_1.3.0
    ## 
    ## loaded via a namespace (and not attached):
    ##   [1] minqa_1.2.4          colorspace_2.0-0     ellipsis_0.3.1      
    ##   [4] ggridges_0.5.2       rsconnect_0.8.16     estimability_1.3    
    ##   [7] markdown_1.1         base64enc_0.1-3      fs_1.5.0            
    ##  [10] rstudioapi_0.13      rstan_2.21.2         DT_0.16             
    ##  [13] fansi_0.4.1          mvtnorm_1.1-1        lubridate_1.7.9.2   
    ##  [16] xml2_1.3.2           codetools_0.2-16     bridgesampling_1.0-0
    ##  [19] splines_4.0.3        knitr_1.30           shinythemes_1.1.2   
    ##  [22] bayesplot_1.7.2      projpred_2.0.2       jsonlite_1.7.1      
    ##  [25] nloptr_1.2.2.2       broom_0.7.2          dbplyr_2.0.0        
    ##  [28] shiny_1.5.0          compiler_4.0.3       httr_1.4.2          
    ##  [31] emmeans_1.5.2-1      backports_1.2.0      assertthat_0.2.1    
    ##  [34] Matrix_1.2-18        fastmap_1.0.1        cli_2.2.0           
    ##  [37] later_1.1.0.1        prettyunits_1.1.1    htmltools_0.5.0     
    ##  [40] tools_4.0.3          igraph_1.2.6         coda_0.19-4         
    ##  [43] gtable_0.3.0         glue_1.4.2           reshape2_1.4.4      
    ##  [46] V8_3.4.0             cellranger_1.1.0     vctrs_0.3.5         
    ##  [49] nlme_3.1-149         crosstalk_1.1.0.1    xfun_0.19           
    ##  [52] ps_1.5.0             lme4_1.1-25          rvest_0.3.6         
    ##  [55] mime_0.9             miniUI_0.1.1.1       lifecycle_0.2.0     
    ##  [58] gtools_3.8.2         statmod_1.4.35       MASS_7.3-53         
    ##  [61] zoo_1.8-8            scales_1.1.1         colourpicker_1.1.0  
    ##  [64] hms_0.5.3            promises_1.1.1       Brobdingnag_1.2-6   
    ##  [67] parallel_4.0.3       inline_0.3.17        shinystan_2.5.0     
    ##  [70] curl_4.3             gamm4_0.2-6          yaml_2.2.1          
    ##  [73] gridExtra_2.3        StanHeaders_2.21.0-6 loo_2.3.1           
    ##  [76] stringi_1.5.3        dygraphs_1.1.1.6     pkgbuild_1.1.0      
    ##  [79] boot_1.3-25          rlang_0.4.9          pkgconfig_2.0.3     
    ##  [82] matrixStats_0.57.0   evaluate_0.14        lattice_0.20-41     
    ##  [85] rstantools_2.1.1     htmlwidgets_1.5.2    processx_3.4.5      
    ##  [88] tidyselect_1.1.0     plyr_1.8.6           magrittr_2.0.1      
    ##  [91] R6_2.5.0             generics_0.1.0       DBI_1.1.0           
    ##  [94] pillar_1.4.7         haven_2.3.1          withr_2.3.0         
    ##  [97] mgcv_1.8-33          xts_0.12.1           abind_1.4-5         
    ## [100] modelr_0.1.8         crayon_1.3.4         utf8_1.1.4          
    ## [103] rmarkdown_2.5        grid_4.0.3           readxl_1.3.1        
    ## [106] callr_3.5.1          threejs_0.3.3        reprex_0.3.0        
    ## [109] digest_0.6.27        xtable_1.8-4         httpuv_1.5.4        
    ## [112] RcppParallel_5.0.2   stats4_4.0.3         munsell_0.5.0       
    ## [115] shinyjs_2.0.0
