---
title: "Chapter 9: Prediction and Bayesian inference"
author: "A Solomon Kurz"
date: "`r format(Sys.Date())`"
output:
  github_document
---

```{r, eval = F, echo = F}
https://github.com/avehtari/ROS-Examples/
```

```{r, echo = F, cache = F}
knitr::opts_chunk$set(fig.retina = 2.5)
knitr::opts_chunk$set(fig.align = "center")
# options(width = 100)
```

# Prediction and Bayesian inference

> Bayesian inference involves three steps that go beyond classical estimation. First, the data and model are combined to form a *posterior distribution*, which we typically summarize by a set of simulations of the *parameters* in the model. Second, we can propagate uncertainty in this distribution--that is, we can get simulation-based *predictions* for unobserved or future outcomes that accounts for uncertainty in the model parameters. Third, we can include additional information into the model using a *prior distribution*. (p. 113, *emphasis* in the original)

## 9.1 Propagating uncertainty in inference using posterior simulations

Once again, we return to model `m7.1` from Chapter 7. First, we'll load the `hibbs.dat` data.

```{r, warning = F, message = F}
library(tidyverse)

hibbs <- 
  read_table2("ROS-Examples-master/ElectionsEconomy/data/hibbs.dat") %>%
  mutate(inc_party_candidate = str_remove_all(inc_party_candidate, '[\"]'),
         other_candidate     = str_remove_all(other_candidate, '[\"]'))
```

Now we load **brms** and the model.

```{r m7.1_09, warning = F, message = F}
library(brms)

m7.1 <-
  brm(data = hibbs,
      vote ~ growth,
      seed = 7,
      file = "fits/m07.01")
```

Here's the summary.

```{r}
print(m7.1, robust = T)
```

These summaries are derived from the posterior simulations, which you can access directly with `posterior_samples()`.

```{r}
post <- posterior_samples(m7.1)

head(post)
```

We can hand-compute the median and mad sd for each using a **tidyverse**-style workflow like this.

```{r, message = F}
post %>% 
  pivot_longer(b_Intercept:sigma) %>% 
  group_by(name) %>% 
  summarise(median = median(value),
            mad_sd = mad(value))
```

### 9.1.1 Uncertainty in the regression coefficients and implied uncertainty in the regression line.

Before we make Figure 9.1, it'll be handy to save a few summary values.

```{r}
med_a <- median(post$b_Intercept)
med_b <- median(post$b_growth)

se_a <- fixef(m7.1, robust = T)[1, 2]
se_b <- fixef(m7.1, robust = T)[2, 2]
```

Now make the two subplots of Figure 9.1.

```{r}
# set the global plotting theme
theme_set(theme_linedraw() +
            theme(panel.grid = element_blank()))

# left
p1 <-
  post %>% 
  ggplot(aes(x = b_Intercept)) +
  geom_histogram(binwidth = 1, boundary = 0, 
                 fill = "grey75", color = "white") +
  geom_vline(xintercept = med_a) +
  geom_segment(x = med_a - se_a, xend = med_a + se_a,
               y = 575, yend = 575,
               arrow = arrow(ends = "both", length = unit(0.25, "cm"))) +
  geom_segment(x = med_a - se_a * 2, xend = med_a + se_a * 2,
               y = 250, yend = 250,
               arrow = arrow(ends = "both", length = unit(0.25, "cm"))) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(subtitle = "Posterior simulations of the intercept, a,\nand posterior median +/− 1 and 2 std err",
       x = "a")

# right
p2 <-
  post %>% 
  ggplot(aes(x = b_growth)) +
  geom_histogram(binwidth = 0.5, boundary = 0, 
                 fill = "grey75", color = "white") +
  geom_vline(xintercept = med_b) +
  geom_segment(x = med_b - se_b, xend = med_b + se_b,
               y = 625, yend = 625,
               arrow = arrow(ends = "both", length = unit(0.25, "cm"))) +
  geom_segment(x = med_b - se_b * 2, xend = med_b + se_b * 2,
               y = 275, yend = 275,
               arrow = arrow(ends = "both", length = unit(0.25, "cm"))) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(subtitle = "Posterior simulations of the intercept, b,\nand posterior median +/− 1 and 2 std err",
       x = "b")
```

Bind the two subplots together with **patchwork** syntax and plot.

```{r, fig.width = 7.5, fig.height = 3.5}
library(patchwork)

p1 + p2
```

The scatter plot of Figure 9.2 is pretty simple.

```{r, fig.width = 3.75, fig.height = 3.5}
p1 <-
  post %>% 
  ggplot(aes(x = b_Intercept, y = b_growth)) +
  geom_point(size = 1/6, alpha = 1/2) +
  labs(subtitle = "Posterior draws of the regression coefficients a, b",
       x = "a",
       y = "b") +
  ylim(0, NA)

p1
```

The spaghetti plot in Figure 9.2b is a little more involved. Here we make it and then combine the two ggplots to make the complete Figure 9.2.

```{r, warning = F, fig.width = 7.5, fig.height = 3.5}
set.seed(9)

p2 <-
  posterior_samples(m7.1) %>% 
  slice_sample(n = 100) %>% 
  
  ggplot() +
  geom_abline(aes(intercept = b_Intercept, slope = b_growth),
              size = 1/4, alpha = 1/2, color = "grey33") +
  geom_point(data = hibbs,
             aes(x = growth, y = vote)) +
  scale_x_continuous("Average recent growth in personal income",
                     breaks = 0:4, labels = function(x) str_c(x, "%"),
                     limits = c(-1, 5), expand = c(0, 0)) +
  scale_y_continuous("Incumbent party's vote share",
                     labels = function(x) str_c(x, "%")) +
  coord_cartesian(ylim = c(43, 62)) +
  labs(subtitle = "Data and 100 posterior draws of the line, y = a + bx",
       x = "x",
       y = "y")

# combine
(p1 + p2) &
  theme(plot.subtitle = element_text(size = 10),
        plot.title.position = "plot")
```

### 9.1.2 Using the matrix of posterior simulations to express uncertainty about a parameter estimate or function of parameter estimates.

Here's a **tidyverse** way to compute the central tendency (median) and spread (mad sd) for a combination of parameters.

```{r}
post %>% 
  mutate(z = b_Intercept / b_growth) %>% 
  summarise(median = median(z),
            mad_sd = mad(z))
```

## 9.2 Prediction and uncertainty: `predict`, `posterior_linpred`, and `posterior_predict`

The **brms** package also includes the `predict()`, `posterior_linpred()`, and `posterior_predict()` functions. On page 115, we learn these will alow us to

* compute "the best point estimate of the average value of $y$ for new data points," $\hat a + \hat b x^\text{new}$;
* compute "the distribution of uncertainty about the expected or average value of $y$ for new data points," $a + b x^\text{new}$ ; and
* compute the "uncertainty about a new observation $y$ with predictors $x^\text{new}$," $a + b x^\text{new} + \text{error}$.

### 9.2.1 Point prediction using predict.

Say we want to use our `m7.1` to predict an incumbent's vote percentage, conditional on 2% economic growth. If we would like a simple point prediction, we can use `brms::predict()`. A key point is we'll need to feed in our `growth` value by way of a data frame or tibble, which we'll call `new`. The `new` data is then fed into the `newdata` argument. If we want the point summarized by a posterior median, rather than a posterior mean, we need to set `robust = TRUE`.

```{r}
new <- tibble(growth = 2.0)

predict(m7.1, 
        newdata = new,
        robust = T)
```

As is typical, **brms** accompanies the point `Estimate` with measures of spread. If we wanted to use the posterior medians of the `a` and `b` parameters to do this by hand, it will probably be easiest to extract these using `fixef()`.

```{r}
a_hat <- fixef(m7.1, robust = T)[1, 1]
b_hat <- fixef(m7.1, robust = T)[2, 1]

a_hat + b_hat * new
```

This method, however, gives a point estimate without any measures of spread.

### 9.2.2 Linear predictor with uncertainty using `posterior_linpred` or `posterior_epred`.

Much like in the text, the `brms::posterior_linpred()` function returns a vector of posterior draws.

```{r}
y_linpred <-
  posterior_linpred(m7.1, 
                    newdata = new,
                    robust = T)

str(y_linpred)
```

We can get these by hand by working directly with `post`.

```{r}
post %>% 
  mutate(growth = 2) %>% 
  mutate(y_linpred = b_Intercept + b_growth * growth) %>% 
  select(y_linpred) %>% 
  head()
```

Happily for y'all **tidyverse** fans, this method returns a tibble.

### 9.2.3 Predictive distribution for a new observation using `posterior_predict`.

The `brms::posterior_predict()` function works very much like the `posterior_linpred()`, from last section.

```{r}
y_pred <-
  posterior_predict(m7.1, 
                    newdata = new,
                    robust = T)

str(y_pred)
```

You can do this by hand, to, by working directly with `post`.

```{r}
post %>% 
  mutate(growth = 2) %>% 
  mutate(y_pred = rnorm(n(), mean = b_Intercept + b_growth * growth, sd = sigma)) %>% 
  select(y_pred) %>% 
  head()
```

Either way, we can now visualize the uncertainty in `y_pred` using a histogram. Here we'll do that with the results from the `posterior_predict()` method.

```{r, fig.width = 3.75, fig.height = 3.25}
tibble(y_pred = y_pred) %>% 
  ggplot(aes(x = y_pred)) +
  geom_histogram(binwidth = 1, boundary = 0, 
                 fill = "grey75", color = "white") +
  scale_y_continuous(NULL, breaks = NULL)
```

Here's a numeric breakdown.

```{r}
tibble(y_pred = y_pred) %>% 
  summarise(median = median(y_pred),
            mad_sd = mad(y_pred),
            win_prob = mean(y_pred > 50))
```

### 9.2.4 Prediction given a range of input values.

We can use these three functions to evaluate the posterior predictions for a range of predictor values. First we define a range of `growth` values.

```{r}
new_grid <- tibble(growth = seq(from = -2.0, to = 4.0, by = 0.5))

glimpse(new_grid)
```

Now plug those into our post-processing functions.

```{r}
y_point_pred_grid <- 
  predict(m7.1, 
          newdata = new_grid,
          robust = T) 

y_linpred_grid <- 
  posterior_linpred(m7.1, 
                    newdata = new_grid,
                    robust = T) 

y_pred_grid <- 
  posterior_predict(m7.1, 
                    newdata = new_grid,
                    robust = T)
```

Use the `str()` function to inspect what we've done.

```{r}
str(y_point_pred_grid)
str(y_linpred_grid)
str(y_pred_grid)
```

The first function, `brms::predict()`, returned a $13 \times 4$ numeric array where the rows indexed each of the 13 `growth` values and the columns are the typical **brms** summary statistics: `Estimate`, `Est.Error`, `Q2.5`, and `Q97.5`. Both `posterior_linpred()` and `posterior_predict()` returned $4{,}000 \times 13$ numeric arrays where the columns marks off the 13 values of `growth` and the rows index the 4,000 posterior draws for each.

### 9.2.5 Propagating uncertainty.

If we want to propagate uncertainty in our predictor, too, it's probably easiest to do with by working with `post` itself. Here we express that uncertainty as $\text{growth} \sim \operatorname{Normal}(2, 0.3)$.

```{r}
post %>% 
  # make the uncertain predictor
  mutate(growth = rnorm(n(), mean = 2.0, sd = 0.3)) %>% 
  # predict
  mutate(y_pred = rnorm(n(), mean = b_Intercept + b_growth * growth, sd = sigma)) %>% 
  # now summarize
  summarise(median = median(y_pred),
            mad_sd = mad(y_pred),
            win_prob = mean(y_pred > 50))
```

### 9.2.6 Simulating uncertainty for the linear predictor and new observations.

Load the `earnings.csv` data.

```{r, warning = F, message = F}
earnings <- read_csv("ROS-Examples-master/Earnings/data/earnings.csv")

glimpse(earnings)
```

Use `brm()` to fit the model, $\text{weight}_i = a + b \text{height}_i + e_i$, using default weak priors.

```{r m9.1, warning = F, message = F}
m9.1 <-
  brm(data = earnings,
      weight ~ height,
      seed = 9,
      file = "fits/m09.01")
```

Check the summary.

```{r}
print(m9.1, robust = T)
```

Since the intercept is difficult to interpret with this parameterization, we might center the predictor.

```{r}
earnings <-
  earnings %>% 
  mutate(c_height = height - 66)
```

Now fit the model, $\text{weight}_i = a + b (\text{height}_i - 66) + e_i$.

```{r m9.2, warning = F, message = F}
m9.2 <-
  brm(data = earnings,
      weight ~ c_height,
      seed = 9,
      file = "fits/m09.02")
```

```{r}
print(m9.2, robust = T)
```

The intercept, `r round(fixef(m9.2)[1, 1], 1)`, is the expected `weight` value when `height == 66`. If we'd like a simple point prediction for `weight` when `c_height == 4`, we might use `brms::predict()`.

```{r}
new <- tibble(c_height = 4.0)

predict(m9.2, 
        newdata = new,
        robust = T)[1]
```

If we'd like simulated draws for the linear predictor, we might use `brms::posterior_linpred()`.

```{r}
posterior_linpred(m9.2, 
                  newdata = new,
                  robust = T) %>% 
  head()
```

If we want a full posterior predictive distribution for new persons of `c_weight == 4`, we'd then use `posterior_predict()`.

```{r}
posterior_predict(m9.2, 
                  newdata = new,
                  robust = T) %>% 
  head()
```

## 9.3 Prior information and Bayesian synthesis.

> Classical statistical methods produce summaries and inferences based on a single dataset. *Bayesian methods* combine a model of the data with *prior information* with the goal of obtaining inferences that are consistent with both sources of information. (p. 119, *emphasis* in the original)

### 9.3.1 Expressing data and prior information on the same scale.

Presuming the normal distribution for both the prior and likelihood, we can express the prior as $\mathcal N (\hat \theta_\text{prior}, \text{se}_\text{prior})$. Similarly, we can express the likelihood as $\mathcal N (\hat \theta_\text{data}, \text{se}_\text{data})$. We can then combine these two forms of information to compute the posterior mean as

$$\hat \theta_\text{Bayes} = \left( \frac{1}{\text{se}_\text{prior}^2} \hat \theta_\text{prior} + \frac{1}{\text{se}_\text{data}^2} \hat \theta_\text{data} \right)  \bigg / \left( \frac{1}{\text{se}_\text{prior}^2} + \frac{1}{\text{se}_\text{data}^2} \right).$$

The formula for the standard error around that posterior mean is

$$\text{se}_\text{Bayes} = 1 \bigg / \sqrt{\frac{1}{\text{se}_\text{prior}^2} + \frac{1}{\text{se}_\text{data}^2}}.$$

The authors also suggested that Bayesian inference may be thought of as a weighted average of the data and the prior.

### 9.3.2 Bayesian information aggregation.

Set our prior values.

```{r}
theta_hat_prior <- 0.524 
se_prior <- 0.041
```

Set the new data estimates.

```{r}
n <- 400
y <- 190
theta_hat_data <- y / n
se_data <- sqrt((y / n) * (1 - y / n) / n)
```

Now compute the posterior values.

```{r}
theta_hat_bayes <- (theta_hat_prior / se_prior^2 + theta_hat_data / se_data^2) / (1 / se_prior^2 + 1 / se_data^2)
se_bayes <- sqrt(1 / (1 / se_prior^2 + 1 / se_data^2))
```

Now we can make our version of Figure 9.3.

```{r, fig.width = 8, fig.height = 2.25}
# define the density values for the prior, likelihood, and posterior
d <-
  tibble(theta = seq(from = 0.35, to = 0.7, length.out = 200)) %>% 
  mutate(prior      = dnorm(theta, mean = theta_hat_prior, sd = se_prior),
         likelihood = dnorm(theta, mean = theta_hat_data,  sd = se_data),
         posterior  = dnorm(theta, mean = theta_hat_bayes, sd = se_bayes))

# this is for the annotation
text <-
  tibble(theta   = c(0.44, 0.58, 0.5),
         density = c(8, 5, 18),
         label   = c("Likelihood", "Prior", "Posterior"),
         hjust   = c(1, 0, 0))
# left
p1 <-
  d %>% 
  ggplot(aes(x = theta)) +
  geom_line(aes(y = prior)) +
  geom_line(aes(y = likelihood)) +
  geom_text(data = filter(text, label != "Posterior"),
            aes(y = density, label = label, hjust = hjust)) +
  scale_x_continuous(expression(theta), breaks = 4:6 / 10, expand = c(0, 0)) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05)))

# right
p2 <-
  d %>% 
  ggplot(aes(x = theta)) +
  geom_line(aes(y = prior),
            size = 1/4) +
  geom_line(aes(y = likelihood),
            size = 1/4) +
  geom_line(aes(y = posterior)) +
  geom_text(data = text,
            aes(y = density, label = label, hjust = hjust)) +
  scale_x_continuous(expression(theta), breaks = 4:6 / 10, expand = c(0, 0)) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05)))

# combine
p1 + p2
```

Here's what happens if we have a less certain likelihood, as expressed by a larger `se_data` value.

```{r, fig.width = 8, fig.height = 2.25}
# less certain se for the likelihood
se_data <- 0.075

# update the posterior
theta_hat_bayes <- (theta_hat_prior / se_prior^2 + theta_hat_data / se_data^2) / (1 / se_prior^2 + 1 / se_data^2)
se_bayes <- sqrt(1 / (1 / se_prior^2 + 1 / se_data^2))

# define the new density values for the prior, likelihood, and posterior
d <-
  tibble(theta = seq(from = 0.35, to = 0.7, length.out = 200)) %>% 
  mutate(prior      = dnorm(theta, mean = theta_hat_prior, sd = se_prior),
         likelihood = dnorm(theta, mean = theta_hat_data,  sd = se_data),
         posterior  = dnorm(theta, mean = theta_hat_bayes, sd = se_bayes))

# this is for the annotation
text <-
  tibble(theta   = c(0.42, 0.56, 0.53),
         density = c(4.7, 7.5, 10.75),
         label   = c("Likelihood", "Prior", "Posterior"),
         hjust   = c(1, 0, 0))
# left
p1 <-
  d %>% 
  ggplot(aes(x = theta)) +
  geom_line(aes(y = prior)) +
  geom_line(aes(y = likelihood)) +
  geom_text(data = filter(text, label != "Posterior"),
            aes(y = density, label = label, hjust = hjust)) +
  scale_x_continuous(expression(theta), breaks = 4:6 / 10, expand = c(0, 0)) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05)))

# right
p2 <-
  d %>% 
  ggplot(aes(x = theta)) +
  geom_line(aes(y = prior),
            size = 1/4) +
  geom_line(aes(y = likelihood),
            size = 1/4) +
  geom_line(aes(y = posterior)) +
  geom_text(data = text,
            aes(y = density, label = label, hjust = hjust)) +
  scale_x_continuous(expression(theta), breaks = 4:6 / 10, expand = c(0, 0)) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05)))

# combine
p1 + p2
```

### 9.3.3 Different ways of assigning prior distributions and performing Bayesian calculations.

> In the general example of regression modeling, we must specify prior information on all the coefficients, which in practice often entails weak priors on coefficients for which we have little knowledge or about which we do not want to make any strong assumptions. (p. 121)

## 9.4 Example of Bayesian inference: beauty and sex ratio

"We can use prior information to refine estimates from noisy studies" (p. 121). The motivation for this example has its origins in a paper by [Kanazawa](https://www.sciencedirect.com/science/article/abs/pii/S0022519306003079).

Load the `sexratio.rda` data.

```{r}
load("ROS-Examples-master/SexRatio/data/sexratio.rda")

head(sexratio)
```

The five attractiveness ratings are displayed in the `x` column. The `y` column contains the percent of adults who were parents of girls, by `x` category. Here they are in a quick plot.

```{r, fig.width = 3.5, fig.height = 2.5}
sexratio %>% 
  ggplot(aes(x = x, y = y, label = y)) +
  geom_hline(yintercept = 50, color = "grey75", size = 1/4) +
  geom_text() +
  scale_y_continuous("% parents of girls", limits = c(0, 100), expand = c(0, 0)) +
  xlab("parental attractiveness rating")
```

### 9.4.1 Prior information.

> More information is available, however. It is well known that the variation in the human sex ratio occurs in a very narrow range. For example, a recent count in the United States reported 48.7% girls among whites and 49.2% among blacks. Similar differences of half of a percentage point or less have been found when comparing based on factors such as birth order, maternal age, or season of birth. Given that attractiveness is itself only subjectively measured, we would find it hard to believe that any difference between more and less attractive parents could be as large as 0.5%. (p. 121)

### 9.4.2 Prior estimate and standard error.

> We can express our scientific knowledge as a prior distribution on $\theta$ with mean 0% and standard deviation 0.25%. The prior mean of zero says that before seeing the data, we would have no reason to expect beautiful parents to have an elevated or depressed rate of girl births. The prior standard deviation of 0.25% says that we find it highly implausible that the true value of $\theta$ is higher than 0.5% or lower than -0.5%. (p. 122)

### 9.4.3 Data estimate and standard error.

> On the percentage scale the survey gives us the estimate $\hat \theta_\text{data} = 8\%$ with standard error $\text{se}_\text{data} = 3\%$, and we can now see that the prior is much more informative than the data: the data standard error is more than 10 times the prior uncertainty. (p. 122)

### 9.4.4 Bayes estimate.

If we use the equations from [Section 9.3.1][Expressing data and prior information on the same scale.], we'll see the is $\hat \theta_\text{Bayes} = 0.06\%$ with $\text{se}_\text{Bayes} = 0.25\%$.

### 9.4.5 Understanding the Bayes estimate.

Recall the total sample size is 3,000 and the proportions all hover around .5.

* We can compute the standard error for a proportion near .5 as $\sqrt{.5 \times .5 / 3{,}000} = 0.009$
* The standard error for the difference between two groups, each of $n = 1{,}500$, may be computed with $\sqrt{p_1 (1 - p_1) / 1{,}500 + p_2 (1 - p_2) / 1{,}500}$. Given a situation where $p_1 \approx p_2 \approx .5$, you can compute this as $\sqrt{2 \times .5 \times .5 / 1{,}500} = 0.018$.
* Because the sample sizes were not equal in the groups, their standard error was a bit larger. Here's how the math shakes out if you set $n = 300$ (i.e., 10% of 3,000) in the "attractive" group: $\sqrt{(.5 \times .5 / 300) + (.5 \times .5 / 2{,}700)} = 0.03$.

## 9.5 Uniform, weakly informative, and informative priors in regression

> In Bayesian inference the likelihood is multiplied by a *prior distribution* to yield a *posterior distribution*, which we take as a summary of our inference given model and data. In this section we consider uniform, weakly informative, and informative prior distributions and how to work with them using ~~`stan_glm`~~ [`brms::brm()`]. (p. 123, *emphasis* in the original)

### 9.5.1 Uniform prior distribution

With the `stan_glm()`, you can fit a model with uniform priors by setting the relevant prior arguments to `NULL`.

```{r, eval = F}
stan_glm(data = hibbs, 
         vote ~ growth, 
         prior_intercept = NULL, prior = NULL, prior_aux = NULL)
```

Though **brms** package is generally quite flexible in the models and priors it supports, it does not fully support flat priors in this way. If you're tricky, you can get close. By default, the priors of `class = b` have a flat prior across the real number line. This is essentially $\operatorname{Uniform}(-\infty, \infty)$. Parameters of `class = Intercept` will not allow for this setting. However, there is a workaround. Recall that one can suppress the default intercept with the `y ~ 0` syntax. **brms** allows users to then add the intercept back in by naming the next parameter `Intercept`, as in `y ~ 0 + Intercept`. The prior for new `Intercept` parameter will be of `class = b`, which will now have a default flat prior just like all other priors of that class.

$\sigma$, however, is not as flexible. By default, **brms** sets the lower bound of $\sigma$ at zero and I am not currently aware of a workaround. I'm also not aware that one can set the upper bound of sigma to positive infinity, which means that one cannot set make $\sigma \sim \operatorname{Uniform}(0, \infty)$. However, one can set use a uniform prior with a very large upper bound, like `1e15` or so. Using that approach, we can express an almost completely flat prior distribution for the model along these lines:

\begin{align*}
\text{votes}_i & \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i  & = a + b\ \text{growth}_i \\
a      & \sim \operatorname{Uniform}(-\infty, \infty) \\
b      & \sim \operatorname{Uniform}(-\infty, \infty) \\
\sigma & \sim \operatorname{Uniform}(0, 10^{15} .
\end{align*}

Here's how to fit that model with `brm()`. Note that because we're using the default flat priors for both `Intercept` and `growth`, there is no need to explicitly state that in the `brm()` function.
      
```{r m9.3, warning = F, message = F}
m9.3 <-
  brm(data = hibbs,
      family = gaussian,
      vote ~ 0 + Intercept + growth,
      prior(uniform(0, 1e15), class = sigma),
      seed = 9,
      file = "fits/m09.03")
```

Check the model summary

```{r}
print(m9.3, robust = T)
```

To make Figure 9.4, we need to collect the posterior draws.

```{r}
post <- 
  posterior_samples(m9.3) %>% 
  # rename
  mutate(a = b_Intercept,
         b = b_growth)

head(post)
```

We can make a **ggplot2** alternative to Gelman et al's wire frame plot with a filled 2D density plot.

```{r, fig.width = 4.5, fig.height = 2.75}
p1 <-
  post %>% 
  ggplot(aes(x = a, y = b)) +
  geom_density2d_filled() + 
  scale_fill_viridis_d("likelihood, p(a, b |y)", option = "A") +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0))  +
  theme(legend.key.size = unit(0.5, 'cm'))

p1
```

```{r, fig.width = 3.75, fig.height = 2.75, eval = F, echo = F}
post %>% 
  ggplot(aes(x = a, y = b)) +
  stat_density_2d(geom = "raster",
                  aes(fill = after_stat(density)),
                  contour = F, interpolate = T) + 
  scale_fill_viridis_c(option = "A", limits = c(0, NA)) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0))
```

Now make the nest two panels and combine all three.

```{r, fig.width = 8, fig.height = 3.25}
p2 <-
  post %>% 
  ggplot(aes(x = a, y = b)) +
  stat_ellipse() +
  geom_point(data = . %>% summarise(a = median(a), b = median(b))) +
  annotate(geom = "text",
           x = c(43.2, 46.8), y = c(5, 2.8),
           label = c("95% interval ellipse", "median"),
           size = 3) +
  scale_x_continuous(expand = c(0, 0), limits = range(post$a)) +
  scale_y_continuous(NULL, breaks = NULL,
                     expand = c(0, 0), limits = range(post$b)) +
  labs(subtitle = expression((hat(a)*", "*hat(b))~and~covariance~matrix))

p3 <-
  post %>% 
  ggplot(aes(x = a, y = b)) +
  geom_point(size = 1/10, alpha = 1/2) +
  scale_x_continuous(expand = c(0, 0), limits = range(post$a)) +
  scale_y_continuous(NULL, breaks = NULL,
                     expand = c(0, 0), limits = range(post$b)) +
  labs(subtitle = expression(4000~posterior~draws~of~(a*", "*b)))

(p1 + 
    labs(subtitle = "likelihood, p(a, b |y)") +
    theme(legend.position = "none")) + 
  p2 + p3
```

### 9.5.2 Default prior distribution.

Though this section is unified in the text, I'm going to split this into four subsections. First, we'll discuss the `rstanarm::stan_glm()` default prior. Second, we'll discuss the `brms::brm()` defaults. Third, we'll compare the two default models using formal statistical notation. Fourth, we'll actually fit a model.

### 9.5.2.1 Default prior distribution by `stan_glm()`.

Gelman et al pointed out `rstanarm::stan_glm()` defaults to giving all regression coefficients a normal prior with a mean of zero and a standard deviation set to $2.5 \operatorname{sd}(y) / \operatorname{sd}(x_k)$, where $k$ indexes the $k$th predictor. Here's what that would be in the case of our current model, `vote ~ growth`.

```{r}
hibbs %>% 
  summarise(prior_sigma = 2.5 * sd(vote) / sd(growth))
```

In other words, the `stan_glm()` default prior for the `growth` $b$-coefficient would be $\mathcal N(0, 10.05)$. The `stan_glm()` default behavior for intercepts is more complicated. It is a normal distribution for which the sigma parameter is set to $2.5 \operatorname{sd}(y)$. Here's that value.

```{r}
hibbs %>% 
  summarise(prior_sigma = 2.5 * sd(vote))
```

The mean of the prior is the expected value in $y$ when all the predictor variables are set to their means,

$$a + b_1 \bar x_1 + b_2 \bar x_2 + \cdots + b_K \bar x_K.$$

We can compute that with a quick data adjustment and a little `lm()`.

```{r}
hibbs <-
  hibbs %>% 
  mutate(c_growth = growth - mean(growth))

lm(data = hibbs,
   vote ~ c_growth) %>% 
  coef()
```

Thus the `stan_glm()` default prior for the intercept is $\mathcal N(52.06, 14.02)$. The default `stan_glm()` prior for $\sigma$ is an exponential distribution with rate $1 / \operatorname{sd}(y)$.

```{r}
hibbs %>% 
  summarise(prior_rate = 1 / sd(vote))
```

We can write that as $\sigma \sim \operatorname{Exponential}(0.178)$.

### 9.5.2.2 Default prior distribution by `brm()`.

We can use the `get_prior()` function to see the default priors for `brm()`.

```{r}
get_prior(data = hibbs,
          family = gaussian,
          vote ~ 1 + growth)
```

As already alluded to, the **brms** default is to set a flat prior on all $b$ parameters, or $b_k \sim \operatorname{Uniform}(-\infty, \infty)$. The default intercept prior for the intercept is a Student-$t$ distribution with a $\nu$ (a.k.a *degrees of freedom*) parameter set to 3, which has rather thick tails. The $\mu$ parameter is set to the median of the criterion variable. Here's that value for our case.

```{r}
median(hibbs$vote)
```

The scale parameter is the mad sd for the criterion.

```{r}
mad(hibbs$vote)
```

Thus, our **brms** default prior for the intercept is $\operatorname{Student-t}(3, 50.1, 6.1)$

It's not well documented, at the moment (see [here](https://github.com/paul-buerkner/brms/issues/1062)), but `brm()` defaults to a half Student-$t$ prior for $sigma$. By "half Student-$t$," I mean the $\mu$ parameter of the prior is set to zero and the lower bound is also zero. The $\nu$ (a.k.a *degrees of freedom*) parameter is set to 3. The scale parameter for the distribution, $\sigma$, is set according to the formula `max(2.5, mad(y))`, where `y` is the criterion variable. In words, the scale parameter is either 2.5 or the mad sd of the criterion, whichever is the highest value. Here's what this in our case.

```{r}
max(2.5, mad(hibbs$vote))
```

Because our mad sd for `vote` is higher than 2.5, that's the default value. Thus, our **brms** default prior for $\sigma$ is $\operatorname{Student-t}^+(3, 0, 6.1)$.

### 9.5.2.3 Compare the two default models.

We can express the model with the `stan_glm()` default priors in statistical notation as

\begin{align*}
\text{votes}_i & \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i & = a + b\ \text{growth}_i \\
a & \sim \operatorname{Normal}(52.06, 14.02) \\
b & \sim \operatorname{Normal}(0, 10.05) \\
\sigma & \sim \operatorname{Exponential}(0.178).
\end{align*}

In contrast, we can express the model with the `brms()` default priors in statistical notation as

\begin{align*}
\text{votes}_i & \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i & = a + b\ \text{growth}_i \\
a & \sim \operatorname{Student-t}(3, 50.8, 6.1) \\
b & \sim \operatorname{Uniform}(-\infty, \infty) \\
\sigma & \sim \operatorname{Student-t}^+(3, 0, 6.1).
\end{align*}

### 9.5.2.4 Fit the default prior model.

If we'd like to use `brm()` to fit a model using the **brms**-based default priors, we just execute code leaving out the `prior` argument.

```{r, eval = F}
m9.4 <-
  brm(data = hibbs,
      family = gaussian,
      vote ~ growth)
```

If we'd like to explicitly set the priors, we'd execute this.

```{r, eval = F}
m9.4 <-
  brm(data = hibbs,
      family = gaussian,
      vote ~ growth,
      prior(student_t(3, 50.8, 6.1), class = Intercept) +
        prior(student_t(3, 0, 6.1), class = sigma))
 
print(m9.4, robust = T) 
```

You'll notice we still didn't include a line for the `b` parameter. If you leave out a prior in your Stan code, it presumes an improper flat prior over the reals, which I'm also describing as $\operatorname{Uniform}(-\infty, \infty)$. We won't be fitting that model, though. Here we'll follow along with the text and fit the model based on the `stan_glm()` default priors.

```{r m9.4}
m9.4 <-
  brm(data = hibbs,
      family = gaussian,
      vote ~ growth,
      # set the priors
      prior(normal(52.06, 14.02), class = Intercept) +
        prior(normal(0, 10.05), class = b) +
        prior(exponential(0.178), class = sigma),
      seed = 9,
      file = "fits/m09.04")
```

Check the model summary.

```{r}
print(m9.4, robust = T) 
```

If you fit the model using the **brms** defaults, instead, you'll see the results are very close.

### 9.5.3 Weakly informative prior distribution based on subject-matter knowledge.

"The default prior is intended to be enough to keep inferences stable. In many problems we can do better by including prior information specific to the problem at hand" (p. 124)

We can express the theory-based model Gelman and colleagues described as


\begin{align*}
\text{votes}_i & \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i & = a + b\ \text{growth}_i \\
a & \sim \operatorname{Normal}(50, 10) \\
b & \sim \operatorname{Normal}(5, 5) \\
\sigma & \sim \operatorname{Exponential}(0.178).
\end{align*}

Fit the model.

```{r m9.5}
m9.5 <-
  brm(data = hibbs,
      family = gaussian,
      vote ~ growth,
      # set the priors
      prior(normal(50, 10), class = Intercept) +
        prior(normal(5, 5), class = b) +
        prior(exponential(0.178), class = sigma),
      seed = 9,
      file = "fits/m09.05")
```

Check the model summary.

```{r}
print(m9.5, robust = T) 
```

It might be easiest to compare the parameter summaries for the three models using a coefficient plot.

```{r, fig.width = 8, fig.height = 1.5}
tibble(fit = str_c("m9.", 3:5)) %>% 
  mutate(summary = map(fit, ~get(.) %>% 
                         posterior_summary(robust = T) %>% 
                         data.frame() %>% 
                         rownames_to_column("parameter"))) %>% 
  unnest(summary) %>% 
  filter(parameter != "lp__") %>% 
  
  ggplot(aes(x = Estimate, xmin = Q2.5, xmax = Q97.5, y = fit)) +
  geom_pointrange() +
  labs(x = "marginal posterior",
       y = NULL) +
  theme(axis.ticks.y = element_blank()) +
  facet_wrap(~parameter, scales = "free_x")
```

Within each panel, the posterior medians are the dots and the horizontal lines mark off the percentile-based 95% intervals. As the authors stated in the text, the results are similar across models.

### 9.5.4 Example where an informative prior makes a difference: Beauty and sex ratio.

Here's the simple OLS model for parental attractiveness predicting precentage of girls.

```{r}
lm(data = sexratio,
   y ~ x) %>% 
  summary()
```

Display the data and the model in our version of Figure 9.5.

```{r, fig.width = 7.25, fig.height = 3, message = F}
p1 <-
  sexratio %>% 
  ggplot(aes(x = x, y = y, label = y)) +
  geom_point() +
  scale_y_continuous("Percentage of girl babies", 
                     breaks = 9:11 * 5, labels = function(x) str_c(x, "%")) +
  labs(subtitle = "Data on beauty and sex ratio",
       x = "Attractiveness of parent")

p2 <-
  sexratio %>% 
  ggplot(aes(x = x, y = y, label = y)) +
  stat_smooth(method = "lm", size = 1/4) +
  geom_point() +
  annotate(geom = "text",
           x = 1, y = 51.5,
           label = "y = 49.4 + 1.5 x\n(Std err of slope is 1.4)",
           size = 3) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(subtitle = "Data and least−squares regression line",
       x = "Attractiveness of parent") +
  coord_cartesian(ylim = range(sexratio$y))

p1 + p2
```

The gray ribbon in the right panel marks of the 95% interval range. With just five data points, it's astonishingly wide. Now fit the model using the **brms** default priors.

```{r m9.6}
m9.6 <-
  brm(data = sexratio,
      family = gaussian,
      y ~ x,
      seed = 9,
      file = "fits/m09.06")
```

Check the model summary.

```{r}
print(m9.6, robust = T) 
```

The results match closely with the `stan_glm()` results in the text.

```{r m9.7}
m9.7 <-
  brm(data = sexratio,
      family = gaussian,
      y ~ x,
      prior(normal(48.8, 0.5), class = Intercept) +
        prior(normal(0, 0.2), class = b),
      seed = 9,
      file = "fits/m09.07")
```

Check the model summary.

```{r}
print(m9.7, robust = T) 
```

These results are much more conservative than the OLS and default prior results. Now we'll compare the two model types with our version of Figure 9.6.

```{r, fig.width = 8, fig.height = 6}
# upper left
p1 <-
  posterior_samples(m9.6) %>% 
  ggplot(aes(x = b_Intercept, y = b_x)) +
  geom_point(size = 1/6, alpha = 1/2) +
  scale_x_continuous(NULL, breaks = NULL) +
  labs(subtitle = "Posterior simulations under default prior",
       y = "Slope, b") +
  coord_cartesian(xlim = c(35, 63),
                  ylim = c(-10, 10))

# lower left
p3 <-
  posterior_samples(m9.7) %>% 
  ggplot(aes(x = b_Intercept, y = b_x)) +
  geom_point(size = 1/6, alpha = 1/2) +
  labs(subtitle = "Posterior simulations under informative prior",
       x = "Intercept, a",
       y = "Slope, b") +
  coord_cartesian(xlim = c(35, 63),
                  ylim = c(-10, 10))

# upper right
set.seed(9)

p2 <-
  posterior_samples(m9.6) %>% 
  slice_sample(n = 100) %>% 
  
  ggplot(aes(x = x, y = y)) +
  geom_abline(aes(intercept = b_Intercept,
                  slope = b_x),
              color = "grey50", size = 1/4, alpha = 1/2) +
  geom_abline(intercept = fixef(m9.6, robust = T)[1, 1], 
              slope = fixef(m9.6, robust = T)[2, 1]) +
  geom_point(data = sexratio) +
  scale_x_continuous(NULL, breaks = NULL) +
  scale_y_continuous("Percentage of girl babies", 
                     breaks = 9:11 * 5, labels = function(x) str_c(x, "%")) +
  labs(subtitle = "Least−squares regression line and\nposterior uncertainty given default prior")

# lower right
set.seed(9)

p4 <-
  posterior_samples(m9.7) %>% 
  slice_sample(n = 100) %>% 
  
  ggplot(aes(x = x, y = y)) +
  geom_abline(aes(intercept = b_Intercept,
                  slope = b_x),
              color = "grey50", size = 1/4, alpha = 1/2) +
  geom_abline(intercept = fixef(m9.7, robust = T)[1, 1], 
              slope = fixef(m9.7, robust = T)[2, 1]) +
  geom_point(data = sexratio) +
  scale_y_continuous("Percentage of girl babies", 
                     breaks = 9:11 * 5, labels = function(x) str_c(x, "%")) +
  labs(subtitle = "Bayes estimated regression line and\nposterior uncertainty given informative prior",
       x = "Attractiveness of parent")

# combine
(p1 + p2 + p3 + p4) &
  theme(plot.subtitle = element_text(hjust = .5))
```

## Session info {-}

```{r}
sessionInfo()
```

```{r, warning = F, echo = F, eval = F}
rm(list = ls())
```

```{r, echo = F, message = F, warning = F, results = "hide", eval = F}
ggplot2::theme_set(ggplot2::theme_grey())
pacman::p_unload(pacman::p_loaded(), character.only = TRUE)
```

